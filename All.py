 
from flask import Flask, render_template, request, jsonify, redirect, url_for
import mysql.connector
import pandas as pd
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend for web applications
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import matplotlib.patches as patches
from datetime import datetime, timedelta
import numpy as np
import io
import base64
import os 

app = Flask(__name__)

# Configure matplotlib for web use
plt.ioff()  # Turn off interactive mode
matplotlib.use('Agg')  # Ensure we use the Agg backend

# Database configuration with timeout settings
DB_CONFIG = {
    'host': "106.51.63.60",
    'user': "mahesh",
    'password': "mahesh_123",
    'database': "historicaldb",
    'connection_timeout': 10,  # 10 seconds timeout
    'autocommit': True,
    'charset': 'utf8mb4'
}

def get_db_connection(max_retries=3):
    """Get database connection with retry logic"""
    for attempt in range(max_retries):
        try:
            connection = mysql.connector.connect(**DB_CONFIG)
            return connection
        except mysql.connector.Error as e:
            print(f"Database connection attempt {attempt + 1} failed: {e}")
            if attempt == max_retries - 1:
                raise
            import time
            time.sleep(1)  # Wait 1 second before retry
    return None

def convert_date_to_db_format(date_str):
    """Convert YYYY-MM-DD format to YYMMDD format for database"""
    try:
        date_obj = datetime.strptime(date_str, '%Y-%m-%d')
        return date_obj.strftime('%y%m%d')
    except ValueError:
        return None

def convert_db_time_to_readable(seconds):
    """Convert seconds since midnight to HH:MM:SS format"""
    hours = seconds // 3600
    minutes = (seconds % 3600) // 60
    secs = seconds % 60
    return f"{hours:02d}:{minutes:02d}:{secs:02d}"

def convert_db_date_to_readable(date_int):
    """Convert YYMMDD or YYYYMMDD format to YYYY-MM-DD format"""
    try:
        date_str = str(date_int)
        if len(date_str) == 6:
            # YYMMDD format
            year = "20" + date_str[:2]
            month = date_str[2:4]
            day = date_str[4:6]
            return f"{year}-{month}-{day}"
        elif len(date_str) == 8:
            # YYYYMMDD format
            year = date_str[:4]
            month = date_str[4:6]
            day = date_str[6:8]
            return f"{year}-{month}-{day}"
        else:
            # Return as-is if format is not recognized
            return str(date_int)
    except Exception as e:
        print(f"Error converting date {date_int}: {e}")
        return str(date_int)

def calculate_vwap(df):
    """Calculate VWAP (Volume Weighted Average Price) for the given dataframe"""
    try:
        print(f"=== STRADDLE VWAP CALCULATION DEBUG ===")
        print(f"DataFrame shape: {df.shape}")
        print(f"DataFrame columns: {list(df.columns)}")
        print(f"First few rows of straddle_high: {df['straddle_high'].head()}")
        print(f"First few rows of straddle_low: {df['straddle_low'].head()}")
        print(f"First few rows of straddle_close: {df['straddle_close'].head()}")
        
        if df is None or len(df) == 0:
            print("DataFrame is None or empty")
            return None
        
        # Calculate typical price (High + Low + Close) / 3
        df['typical_price'] = (df['straddle_high'] + df['straddle_low'] + df['straddle_close']) / 3
        print(f"Typical price calculated, first few values: {df['typical_price'].head()}")
        
        # Calculate cumulative volume (assuming equal volume for each data point)
        # In real scenarios, you'd have actual volume data
        df['volume'] = 1  # Default volume of 1 for each data point
        
        # Calculate cumulative values
        df['cumulative_tp_volume'] = (df['typical_price'] * df['volume']).cumsum()
        df['cumulative_volume'] = df['volume'].cumsum()
        
        # Calculate VWAP
        df['vwap'] = df['cumulative_tp_volume'] / df['cumulative_volume']
        print(f"VWAP calculated, first few values: {df['vwap'].head()}")
        print(f"VWAP final values shape: {df['vwap'].values.shape}")
        
        return df['vwap'].values
        
    except Exception as e:
        print(f"Error calculating VWAP: {e}")
        import traceback
        traceback.print_exc()
        return None

def calculate_vwap_regular(df):
    """Calculate VWAP (Volume Weighted Average Price) for regular OHLC data"""
    try:
        print(f"=== VWAP CALCULATION DEBUG ===")
        print(f"DataFrame shape: {df.shape}")
        print(f"DataFrame columns: {list(df.columns)}")
        print(f"First few rows of high: {df['high'].head()}")
        print(f"First few rows of low: {df['low'].head()}")
        print(f"First few rows of close: {df['close'].head()}")
        
        if df is None or len(df) == 0:
            print("DataFrame is None or empty")
            return None
        
        # Calculate typical price (High + Low + Close) / 3
        df['typical_price'] = (df['high'] + df['low'] + df['close']) / 3
        print(f"Typical price calculated, first few values: {df['typical_price'].head()}")
        
        # Calculate cumulative volume (assuming equal volume for each data point)
        # In real scenarios, you'd have actual volume data
        df['volume'] = 1  # Default volume of 1 for each data point
        
        # Calculate cumulative values
        df['cumulative_tp_volume'] = (df['typical_price'] * df['volume']).cumsum()
        df['cumulative_volume'] = df['volume'].cumsum()
        
        # Calculate VWAP
        df['vwap'] = df['cumulative_tp_volume'] / df['cumulative_volume']
        print(f"VWAP calculated, first few values: {df['vwap'].head()}")
        print(f"VWAP final values shape: {df['vwap'].values.shape}")
        
        return df['vwap'].values
        
    except Exception as e:
        print(f"Error calculating VWAP: {e}")
        import traceback
        traceback.print_exc()
        return None

def calculate_ema(df, period=20, price_column='close'):
    """Calculate EMA (Exponential Moving Average) for the given dataframe and period"""
    try:
        print(f"=== EMA {period} CALCULATION DEBUG ===")
        print(f"DataFrame shape: {df.shape}")
        print(f"Price column: {price_column}")
        print(f"First few rows of {price_column}: {df[price_column].head()}")
        
        if df is None or len(df) == 0:
            print("DataFrame is None or empty")
            return None
        
        if len(df) < period:
            print(f"Not enough data points for EMA {period}. Need at least {period} points, got {len(df)}")
            return None
        
        # Calculate the smoothing factor
        alpha = 2.0 / (period + 1)
        print(f"EMA {period} alpha (smoothing factor): {alpha}")
        
        # Initialize EMA with the first value
        ema_values = [df[price_column].iloc[0]]
        
        # Calculate EMA for remaining values
        for i in range(1, len(df)):
            ema = alpha * df[price_column].iloc[i] + (1 - alpha) * ema_values[-1]
            ema_values.append(ema)
        
        print(f"EMA {period} calculated, first few values: {ema_values[:5]}")
        print(f"EMA {period} final values shape: {len(ema_values)}")
        print(f"EMA {period} value range: {min(ema_values):.2f} to {max(ema_values):.2f}")
        
        return ema_values
        
    except Exception as e:
        print(f"Error calculating EMA {period}: {e}")
        import traceback
        traceback.print_exc()
        return None

def calculate_sma(df, period=20):
    """Calculate Simple Moving Average for the given dataframe"""
    try:
        if df is None or len(df) == 0:
            return None
        
        # Calculate SMA using closing prices
        sma = df['straddle_close'].rolling(window=period).mean()
        return sma.values
        
    except Exception as e:
        print(f"Error calculating SMA: {e}")
        return None


def get_date_range(data_type, symbol='nifty'):
    """Get the actual date range (min and max dates) from the database"""
    try:
        print(f"=== GET_DATE_RANGE DEBUG ===")
        print(f"  data_type: {data_type}")
        print(f"  symbol: {symbol}")
        
        # Check cache first
        cache_key = f"{symbol}_{data_type}"
        if cache_key in _date_range_cache:
            print(f"  returning CACHED date range for {cache_key}")
            return _date_range_cache[cache_key]
        
        connection = get_db_connection()
        cursor = connection.cursor()
        
        # Determine table name based on data type and symbol
        table_map = {
            'nifty': {
                'nifty_cash': 'nifty_cash',
                'nifty_future': 'nifty_future',
                'nifty_call': 'nifty_call',
                'nifty_put': 'nifty_put'
            },
            'banknifty': {
                'banknifty_cash': 'banknifty_cash',
                'banknifty_future': 'banknifty_future',
                'banknifty_call': 'banknifty_call',
                'banknifty_put': 'banknifty_put'
            },
            'midcpnifty': {
                'midcpnifty_cash': 'midcpnifty_cash',
                'midcpnifty_future': 'midcpnifty_future',
                'midcpnifty_call': 'midcpnifty_call',
                'midcpnifty_put': 'midcpnifty_put'
            },
            'sensex': {
                'sensex_cash': 'sensex_cash',
                'sensex_future': 'sensex_future',
                'sensex_call': 'sensex_call',
                'sensex_put': 'sensex_put'
            }
        }
        
        symbol_tables = table_map.get(symbol, table_map['nifty'])
        table_name = symbol_tables.get(data_type, list(symbol_tables.values())[0])
        
        print(f"  selected table_name: {table_name}")
        print(f"  available tables for symbol '{symbol}': {list(symbol_tables.keys())}")
        print(f"  requested data_type: {data_type}")
        
        # Get min and max dates
        query = f"SELECT MIN(date) as min_date, MAX(date) as max_date FROM {table_name}"
        print(f"  executing query: {query}")
        
        # First, let's check if the table exists and has any data
        check_query = f"SELECT COUNT(*) as row_count FROM {table_name}"
        print(f"  checking table existence with: {check_query}")
        cursor.execute(check_query)
        count_result = cursor.fetchone()
        print(f"  table row count: {count_result[0] if count_result else 'None'}")
        
        # Also list all available tables for debugging
        try:
            cursor.execute("SHOW TABLES")
            all_tables = cursor.fetchall()
            table_names = [table[0] for table in all_tables]
            print(f"  Available tables in database: {table_names}")
        except Exception as e:
            print(f"  Error listing tables: {e}")
        
        cursor.execute(query)
        result = cursor.fetchone()
        
        # If no data found, try alternative table names
        if not result or not result[0] or not result[1]:
            print(f"  No data found in {table_name}, trying alternative tables...")
            
            # Try common table name variations
            alternative_tables = [
                f"{symbol}_cash",
                f"{symbol}_future", 
                f"{symbol}_call",
                f"{symbol}_put",
                f"{data_type}",
                "nifty_cash"  # fallback to nifty_cash
            ]
            
            for alt_table in alternative_tables:
                if alt_table == table_name:
                    continue  # Skip the one we already tried
                    
                try:
                    print(f"  Trying alternative table: {alt_table}")
                    alt_query = f"SELECT COUNT(*) as row_count FROM {alt_table}"
                    cursor.execute(alt_query)
                    alt_count = cursor.fetchone()
                    
                    if alt_count and alt_count[0] > 0:
                        print(f"  Found data in {alt_table} with {alt_count[0]} rows")
                        # Use this table instead
                        query = f"SELECT MIN(date) as min_date, MAX(date) as max_date FROM {alt_table}"
                        print(f"  executing alternative query: {query}")
                        cursor.execute(query)
                        result = cursor.fetchone()
                        table_name = alt_table  # Update table name for logging
                        break
                    else:
                        print(f"  No data in {alt_table}")
                except Exception as e:
                    print(f"  Error checking {alt_table}: {e}")
                    continue
        
        if result and result[0] and result[1]:
            min_date = convert_db_date_to_readable(result[0])
            max_date = convert_db_date_to_readable(result[1])
            
            print(f"  raw result: {result}")
            print(f"  min_date_int: {result[0]} -> {min_date}")
            print(f"  max_date_int: {result[1]} -> {max_date}")
            print(f"  date range: {min_date} to {max_date}")
            
            # Validate the converted dates
            try:
                from datetime import datetime
                test_min = datetime.strptime(min_date, '%Y-%m-%d')
                test_max = datetime.strptime(max_date, '%Y-%m-%d')
                print(f"  date validation: PASSED")
            except Exception as e:
                print(f"  date validation: FAILED - {e}")
                return None
            
            date_range_result = {
                'min_date': min_date,
                'max_date': max_date,
                'min_date_int': result[0],
                'max_date_int': result[1]
            }
            
            # Cache the result for future requests
            _date_range_cache[cache_key] = date_range_result
            print(f"  cached date range for {cache_key}")
            
            return date_range_result
        else:
            print(f"  no date range found - result: {result}")
            return None
        
    except mysql.connector.Error as err:
        print(f"Database error: {err}")
        return None
    finally:
        if 'connection' in locals():
            cursor.close()
            connection.close()

# Simple cache for available dates and date ranges to avoid repeated database calls
_dates_cache = {}
_date_range_cache = {}

def get_available_dates(data_type, symbol='nifty'):
    """Get list of available dates based on data type and symbol"""
    try:
        print(f"=== GET_AVAILABLE_DATES DEBUG ===")
        print(f"  data_type: {data_type}")
        print(f"  symbol: {symbol}")
        
        # Check cache first
        cache_key = f"{symbol}_{data_type}"
        if cache_key in _dates_cache:
            print(f"  returning CACHED dates for {cache_key}: {len(_dates_cache[cache_key])} dates")
            return _dates_cache[cache_key]
        
        connection = get_db_connection()
        cursor = connection.cursor()
        
        # Determine table name based on data type and symbol
        table_map = {
            'nifty': {
                'nifty_cash': 'nifty_cash',
                'nifty_future': 'nifty_future',
                'nifty_call': 'nifty_call',
                'nifty_put': 'nifty_put'
            },
            'banknifty': {
                'banknifty_cash': 'banknifty_cash',
                'banknifty_future': 'banknifty_future',
                'banknifty_call': 'banknifty_call',
                'banknifty_put': 'banknifty_put'
            },
            'midcpnifty': {
                'midcpnifty_cash': 'midcpnifty_cash',
                'midcpnifty_future': 'midcpnifty_future',
                'midcpnifty_call': 'midcpnifty_call',
                'midcpnifty_put': 'midcpnifty_put'
            },
            'sensex': {
                'sensex_cash': 'sensex_cash',
                'sensex_future': 'sensex_future',
                'sensex_call': 'sensex_call',
                'sensex_put': 'sensex_put'
            }
        }
        
        symbol_tables = table_map.get(symbol, table_map['nifty'])
        table_name = symbol_tables.get(data_type, list(symbol_tables.values())[0])
        
        print(f"  symbol_tables: {symbol_tables}")
        print(f"  selected table_name: {table_name}")
        
        # Check if this is options data and handle differently
        is_options_data = data_type.endswith('_call') or data_type.endswith('_put')
        
        # Use optimized query for all data types to improve performance
        # This query is more efficient on large tables with many duplicate dates
        query = f"SELECT DISTINCT date FROM {table_name} WHERE date IS NOT NULL ORDER BY date ASC"
        
        if is_options_data:
            print(f"  executing OPTIMIZED OPTIONS query: {query}")
        else:
            print(f"  executing STANDARD query: {query}")
        
        cursor.execute(query)
        results = cursor.fetchall()
        
        print(f"  raw query results: {len(results)} rows")
        
        # Convert to readable dates and ensure uniqueness
        date_set = set()  # Use set to ensure no duplicates
        for row in results:
            date_int = row[0]
            if date_int:  # Skip null dates
                readable_date = convert_db_date_to_readable(date_int)
                date_set.add(readable_date)
        
        # Convert back to sorted list
        dates = sorted(list(date_set))
        
        print(f"  unique dates after processing: {len(dates)}")
        print(f"  first 5 dates: {dates[:5] if dates else 'None'}")
        print(f"  last 5 dates: {dates[-5:] if dates else 'None'}")
        
        if is_options_data:
            print(f"  OPTIONS DATA DEBUG: {data_type}")
            print(f"    Raw results: {len(results)}")
            print(f"    Unique dates: {len(dates)}")
            if len(results) != len(dates):
                print(f"    WARNING: Raw results ({len(results)}) != Unique dates ({len(dates)})")
                print(f"    This suggests duplicate dates in options table")
        
        # Cache the results for future requests
        _dates_cache[cache_key] = dates
        print(f"  cached {len(dates)} dates for {cache_key}")
        
        return dates
        
    except mysql.connector.Error as err:
        print(f"Database error: {err}")
        return []
    finally:
        if 'connection' in locals():
            cursor.close()
            connection.close()

def get_available_strikes(date, data_type, symbol='nifty'):
    """Get available strike prices for a given date and data type"""
    try:
        # Check if it's a valid options data type for the given symbol
        valid_options_types = {
            'nifty': ['nifty_call', 'nifty_put'],
            'banknifty': ['banknifty_call', 'banknifty_put'],
            'midcpnifty': ['midcpnifty_call', 'midcpnifty_put'],
            'sensex': ['sensex_call', 'sensex_put']
        }
        
        if symbol not in valid_options_types or data_type not in valid_options_types[symbol]:
            print(f"Invalid options data type '{data_type}' for symbol '{symbol}'")
            return []
        
        connection = get_db_connection()
        cursor = connection.cursor()
        db_date = convert_date_to_db_format(date)
        
        cursor.execute(f"SELECT DISTINCT strike FROM {data_type} WHERE date = %s ORDER BY strike", (db_date,))
        strikes = [row[0] for row in cursor.fetchall()]
        
        cursor.close()
        connection.close()
        
        return strikes
        
    except Exception as e:
        print(f"Error getting available strikes: {e}")
        return []

def get_available_expiries(date, data_type, strike, symbol='nifty'):
    """Get available expiry dates for a given date, data type, and strike"""
    try:
        # Check if it's a valid options data type for the given symbol
        valid_options_types = {
            'nifty': ['nifty_call', 'nifty_put'],
            'banknifty': ['banknifty_call', 'banknifty_put'],
            'midcpnifty': ['midcpnifty_call', 'midcpnifty_put'],
            'sensex': ['sensex_call', 'sensex_put']
        }
        
        if symbol not in valid_options_types or data_type not in valid_options_types[symbol]:
            print(f"Invalid options data type '{data_type}' for symbol '{symbol}'")
            return []
        
        connection = get_db_connection()
        cursor = connection.cursor()
        db_date = convert_date_to_db_format(date)
        
        cursor.execute(f"SELECT DISTINCT expiry FROM {data_type} WHERE date = %s AND strike = %s ORDER BY expiry", (db_date, strike))
        expiries = [row[0] for row in cursor.fetchall()]
        
        cursor.close()
        connection.close()
        
        return expiries
        
    except Exception as e:
        print(f"Error getting available expiries: {e}")
        return []

def get_ohlc_data_for_date(date, data_type, strike=None, expiry=None, symbol='nifty'):
    """Get OHLC data for a specific date and data type"""
    try:
        db_date = convert_date_to_db_format(date)
        if db_date is None:
            return None
        
        connection = get_db_connection()
        cursor = connection.cursor()
        
        # Determine table name based on data type and symbol
        table_map = {
            'nifty': {
                'nifty_cash': 'nifty_cash',
                'nifty_future': 'nifty_future',
                'nifty_call': 'nifty_call',
                'nifty_put': 'nifty_put'
            },
            'banknifty': {
                'banknifty_cash': 'banknifty_cash',
                'banknifty_future': 'banknifty_future',
                'banknifty_call': 'banknifty_call',
                'banknifty_put': 'banknifty_put'
            },
            'midcpnifty': {
                'midcpnifty_cash': 'midcpnifty_cash',
                'midcpnifty_future': 'midcpnifty_future',
                'midcpnifty_call': 'midcpnifty_call',
                'midcpnifty_put': 'midcpnifty_put'
            },
            'sensex': {
                'sensex_cash': 'sensex_cash',
                'sensex_future': 'sensex_future',
                'sensex_call': 'sensex_call',
                'sensex_put': 'sensex_put'
            }
        }
        
        symbol_tables = table_map.get(symbol, table_map['nifty'])
        table_name = symbol_tables.get(data_type, list(symbol_tables.values())[0])
        
        # For options, include strike and expiry in the query
        if symbol == 'nifty' and data_type in ['nifty_call', 'nifty_put'] and strike and expiry:
            query = f"SELECT * FROM {table_name} WHERE date = %s AND strike = %s AND expiry = %s ORDER BY time"
            cursor.execute(query, (db_date, strike, expiry))
        elif symbol == 'banknifty' and data_type in ['banknifty_call', 'banknifty_put'] and strike and expiry:
            query = f"SELECT * FROM {table_name} WHERE date = %s AND strike = %s AND expiry = %s ORDER BY time"
            cursor.execute(query, (db_date, strike, expiry))
        elif symbol == 'midcpnifty' and data_type in ['midcpnifty_call', 'midcpnifty_put'] and strike and expiry:
            query = f"SELECT * FROM {table_name} WHERE date = %s AND strike = %s AND expiry = %s ORDER BY time"
            cursor.execute(query, (db_date, strike, expiry))
        elif symbol == 'sensex' and data_type in ['sensex_call', 'sensex_put'] and strike and expiry:
            query = f"SELECT * FROM {table_name} WHERE date = %s AND strike = %s AND expiry = %s ORDER BY time"
            cursor.execute(query, (db_date, strike, expiry))
        else:
            query = f"SELECT * FROM {table_name} WHERE date = %s ORDER BY time"
            cursor.execute(query, (db_date,))
        
        results = cursor.fetchall()
        
        if not results:
            return None
        
        # Get column names
        columns = [desc[0] for desc in cursor.description]
        
        # Create DataFrame
        df = pd.DataFrame(results, columns=columns)
        
        # Debug: Print raw database values
        print(f"DEBUG: Raw database values (first 3 rows):")
        if len(df) > 0:
            print(f"  Columns: {list(df.columns)}")
            print(f"  Shape: {df.shape}")
            print(f"  First 3 rows OHLC:")
            for i in range(min(3, len(df))):
                print(f"    Row {i}: Open={df.iloc[i]['open']}, High={df.iloc[i]['high']}, Low={df.iloc[i]['low']}, Close={df.iloc[i]['close']}")
        
        # Filter out records with missing OHLC data and inconsistent values
        if len(df) > 0:
            original_count = len(df)
            # Remove rows where any OHLC value is null or 0
            df = df.dropna(subset=['open', 'high', 'low', 'close'])
            df = df[(df['open'] > 0) & (df['high'] > 0) & (df['low'] > 0) & (df['close'] > 0)]
            
            # Additional filtering: Remove records with unrealistic values (too small or too large)
            # Only apply realistic value filtering for BANKNIFTY data types
            if 'symbol' in df.columns and data_type in ['banknifty_cash', 'banknifty_future']:
                banknifty_mask = df['symbol'] == 'BANKNIFTY'
                if banknifty_mask.any():
                    # For BANKNIFTY, values should be in reasonable range (40,000-70,000 before scaling)
                    realistic_mask = (
                        (df['open'] >= 4000000) & (df['open'] <= 7000000) &
                        (df['high'] >= 4000000) & (df['high'] <= 7000000) &
                        (df['low'] >= 4000000) & (df['low'] <= 7000000) &
                        (df['close'] >= 4000000) & (df['close'] <= 7000000)
                    )
                    df = df[realistic_mask | ~banknifty_mask]
            
            filtered_count = len(df)
            print(f"DEBUG: Filtered data - Original: {original_count}, After filtering: {filtered_count}")
            
            if len(df) == 0:
                print("ERROR: No valid OHLC data after filtering")
                return None
        
        # Convert database formats back to readable formats
        if 'date' in df.columns:
            df['date_readable'] = df['date'].apply(convert_db_date_to_readable)
        if 'time' in df.columns:
            df['time_readable'] = df['time'].apply(convert_db_time_to_readable)
        
        return df
        
    except mysql.connector.Error as err:
        print(f"Database error: {err}")
        return None
    finally:
        if 'connection' in locals():
            cursor.close()
            connection.close()

def calculate_time_frame(df):
    """Calculate time frame information from the data"""
    try:
        print(f"=== CALCULATE_TIME_FRAME DEBUG ===")
        print(f"DataFrame columns: {list(df.columns)}")
        print(f"DataFrame shape: {df.shape}")
        print(f"First few rows:")
        print(df.head(3))
        
        # Get the first and last time entries
        first_time = df['time_readable'].iloc[0]
        last_time = df['time_readable'].iloc[-1]
        
        print(f"First time: {first_time}, Last time: {last_time}")
        
        # Calculate trading duration
        if 'time' in df.columns:
            first_seconds = df['time'].iloc[0]
            last_seconds = df['time'].iloc[-1]
            duration_seconds = last_seconds - first_seconds
            print(f"First seconds: {first_seconds}, Last seconds: {last_seconds}, Duration: {duration_seconds}")
        else:
            print("ERROR: 'time' column not found in DataFrame!")
            print("Available columns:", list(df.columns))
            return {
                'market_open': 'N/A',
                'market_close': 'N/A',
                'trading_duration': 'N/A',
                'data_intervals': 'N/A'
            }
        
        # Convert duration to hours and minutes
        hours = duration_seconds // 3600
        minutes = (duration_seconds % 3600) // 60
        
        # Format duration
        if hours > 0:
            duration_str = f"{hours}h {minutes}m"
        else:
            duration_str = f"{minutes}m"
        
        # Calculate data intervals
        if len(df) > 1:
            interval_seconds = (last_seconds - first_seconds) / (len(df) - 1)
            if interval_seconds < 60:
                interval_str = f"{int(interval_seconds)}s"
            elif interval_seconds < 3600:
                interval_str = f"{int(interval_seconds // 60)}m"
            else:
                interval_str = f"{int(interval_seconds // 3600)}h"
        else:
            interval_str = "N/A"
        
        return {
            'market_open': first_time,
            'market_close': last_time,
            'trading_duration': duration_str,
            'data_intervals': interval_str
        }
        
    except Exception as e:
        print(f"Error calculating time frame: {e}")
        return {
            'market_open': 'N/A',
            'market_close': 'N/A',
            'trading_duration': 'N/A',
            'data_intervals': 'N/A'
        }

def resample_ohlc_data(df, interval_minutes, data_type='nifty_cash'):
    """Resample 1-minute OHLC data to specified interval"""
    if df is None or len(df) == 0:
        return None
    
    try:
        print(f"DEBUG: Resampling {len(df)} records to {interval_minutes}-minute intervals")
        
        # Create datetime index for resampling
        df['datetime'] = pd.to_datetime(df['date_readable'] + ' ' + df['time_readable'])
        df.set_index('datetime', inplace=True)
        
        print(f"DEBUG: Original time range: {df.index[0]} to {df.index[-1]}")
        
        # Debug: Print original values before scaling
        print(f"DEBUG: Original OHLC values (first 5 rows):")
        print(f"  Open: {df['open'].head().tolist()}")
        print(f"  High: {df['high'].head().tolist()}")
        print(f"  Low: {df['low'].head().tolist()}")
        print(f"  Close: {df['close'].head().tolist()}")
        
        # Scale down OHLC values by dividing by 100 (convert from paise to rupees)
        df_scaled = df.copy()
        
        # Check if data is already in rupees (for options data)
        if data_type in ['nifty_call', 'nifty_put', 'banknifty_call', 'banknifty_put', 'midcpnifty_call', 'midcpnifty_put', 'sensex_call', 'sensex_put']:
            # For options data, check if values are already in rupees (small values)
            sample_values = df['open'].head(5).tolist()
            print(f"DEBUG: Options sample values: {sample_values}")
            if all(val < 1000 for val in sample_values):
                print("DEBUG: Options data already in rupees, no scaling needed")
                # Data is already in rupees, no scaling needed
                df_scaled['open'] = df['open']
                df_scaled['high'] = df['high']
                df_scaled['low'] = df['low']
                df_scaled['close'] = df['close']
            else:
                print("DEBUG: Options data in paise, scaling by 100")
                df_scaled['open'] = df['open'] / 100
                df_scaled['high'] = df['high'] / 100
                df_scaled['low'] = df['low'] / 100
                df_scaled['close'] = df['close'] / 100
        else:
            # For cash/future data, always scale by 100
            print("DEBUG: Cash/Future data scaling by 100")
        df_scaled['open'] = df['open'] / 100
        df_scaled['high'] = df['high'] / 100
        df_scaled['low'] = df['low'] / 100
        df_scaled['close'] = df['close'] / 100
        
        # Debug: Print scaling results
        print(f"DEBUG: Scaling results (first 3 rows):")
        print(f"  Original Open: {df['open'].head(3).tolist()}")
        print(f"  Scaled Open: {df_scaled['open'].head(3).tolist()}")
        print(f"  Original High: {df['high'].head(3).tolist()}")
        print(f"  Scaled High: {df_scaled['high'].head(3).tolist()}")
        print(f"  Original Low: {df['low'].head(3).tolist()}")
        print(f"  Scaled Low: {df_scaled['low'].head(3).tolist()}")
        print(f"  Original Close: {df['close'].head(3).tolist()}")
        print(f"  Scaled Close: {df_scaled['close'].head(3).tolist()}")
        
        # For options data, filter out unrealistic small values that are likely data errors
        if data_type in ['nifty_call', 'nifty_put', 'banknifty_call', 'banknifty_put', 'midcpnifty_call', 'midcpnifty_put', 'sensex_call', 'sensex_put']:
            print(f"DEBUG: Filtering unrealistic values for options data...")
            original_count = len(df_scaled)
            
            # For options, use flexible range based on actual data values
            all_values = pd.concat([df_scaled['open'], df_scaled['high'], df_scaled['low'], df_scaled['close']])
            min_val = all_values.min()
            max_val = all_values.max()
            
            print(f"DEBUG: Options data range - min: {min_val}, max: {max_val}")
            
            # Use flexible thresholds that work for both small and large option values
            # Check if data is consistently large or small, not mixed
            if max_val > 1000 and min_val > 100:  # All values are large (like call data)
                # For large option values (like 3800+), use broader range
                lower_limit = 0.01
                upper_limit = max(10000, max_val * 1.5)  # At least 10000, or 1.5x max value
                print(f"DEBUG: Using large options range ({lower_limit} to {upper_limit})")
            elif max_val < 1000 and min_val > 0.1:  # All values are small (like put data)
                # For small option values, use normal range
                lower_limit = 0.01
                upper_limit = 1000
                print(f"DEBUG: Using small options range ({lower_limit} to {upper_limit})")
            else:
                # Mixed data or edge cases - use very permissive range
                lower_limit = 0.01
                upper_limit = max(10000, max_val * 2)  # Very permissive
                print(f"DEBUG: Using mixed/permissive options range ({lower_limit} to {upper_limit})")
            
            valid_mask = (
                (df_scaled['open'] >= lower_limit) & (df_scaled['open'] <= upper_limit) &
                (df_scaled['high'] >= lower_limit) & (df_scaled['high'] <= upper_limit) &
                (df_scaled['low'] >= lower_limit) & (df_scaled['low'] <= upper_limit) &
                (df_scaled['close'] >= lower_limit) & (df_scaled['close'] <= upper_limit)
            )
            
            df_scaled = df_scaled[valid_mask]
            filtered_count = len(df_scaled)
            print(f"DEBUG: Options data filtering - Original: {original_count}, After filtering: {filtered_count}")
            
            if len(df_scaled) == 0:
                print("ERROR: No valid options data after filtering unrealistic values")
                return None
            
            # Debug: Print filtered values
            print(f"DEBUG: Filtered OHLC values (first 5 rows):")
            print(f"  Open: {df_scaled['open'].head().tolist()}")
            print(f"  High: {df_scaled['high'].head().tolist()}")
            print(f"  Low: {df_scaled['low'].head().tolist()}")
            print(f"  Close: {df_scaled['close'].head().tolist()}")
        
        # Debug: Print scaled values after scaling
        print(f"DEBUG: Scaled OHLC values (first 5 rows):")
        print(f"  Open: {df_scaled['open'].head().tolist()}")
        print(f"  High: {df_scaled['high'].head().tolist()}")
        print(f"  Low: {df_scaled['low'].head().tolist()}")
        print(f"  Close: {df_scaled['close'].head().tolist()}")
        
        # Additional filtering: Remove records with unrealistic values after scaling
        print(f"DEBUG: Additional filtering after scaling...")
        original_scaled_count = len(df_scaled)
        
        # Only apply BANKNIFTY-specific filtering for BANKNIFTY data types
        if 'symbol' in df_scaled.columns and data_type in ['banknifty_cash', 'banknifty_future']:
            banknifty_mask = df_scaled['symbol'] == 'BANKNIFTY'
            if banknifty_mask.any():
                # Filter out records with unrealistic values after scaling
                realistic_mask = (
                    (df_scaled['open'] >= 40000) & (df_scaled['open'] <= 70000) &
                    (df_scaled['high'] >= 40000) & (df_scaled['high'] <= 70000) &
                    (df_scaled['low'] >= 40000) & (df_scaled['low'] <= 70000) &
                    (df_scaled['close'] >= 40000) & (df_scaled['close'] <= 70000)
                )
                df_scaled = df_scaled[realistic_mask | ~banknifty_mask]
                print(f"DEBUG: After scaling filter - Original: {original_scaled_count}, Filtered: {len(df_scaled)}")
        
        # Resample data to specified interval using simple and correct aggregation
        print(f"DEBUG: Using resampling rule: '{interval_minutes}min'")
        
        # Filter out records with mixed data before resampling
        # Separate logic for options data vs cash/future data
        if len(df_scaled) > 0:
            if data_type in ['nifty_call', 'nifty_put', 'banknifty_call', 'banknifty_put', 'midcpnifty_call', 'midcpnifty_put', 'sensex_call', 'sensex_put']:
                # ===== OPTIONS DATA LOGIC (CALL/PUT) =====
                print("DEBUG: Applying OPTIONS data filtering logic")
                
                # Check for mixed data by looking at the range of values
                all_values = pd.concat([df_scaled['open'], df_scaled['high'], df_scaled['low'], df_scaled['close']])
                min_val = all_values.min()
                max_val = all_values.max()
                
                # Use the same flexible range logic as in the initial filtering
                if max_val > 1000 and min_val > 100:  # All values are large (like call data)
                    # For large option values (like 1800+), use broader range
                    lower_limit = 0.01
                    upper_limit = max(10000, max_val * 1.5)  # At least 10000, or 1.5x max value
                    print(f"DEBUG: Using large options range for mixed data filtering ({lower_limit} to {upper_limit})")
                elif max_val < 1000 and min_val > 0.1:  # All values are small (like put data)
                    # For small option values, use normal range
                    lower_limit = 0.01
                    upper_limit = 1000
                    print(f"DEBUG: Using small options range for mixed data filtering ({lower_limit} to {upper_limit})")
                else:
                    # Mixed data or edge cases - use very permissive range
                    lower_limit = 0.01
                    upper_limit = max(10000, max_val * 2)  # Very permissive
                    print(f"DEBUG: Using mixed/permissive options range for mixed data filtering ({lower_limit} to {upper_limit})")
                
                valid_mask = (
                    (df_scaled['open'] >= lower_limit) & (df_scaled['open'] <= upper_limit) &
                    (df_scaled['high'] >= lower_limit) & (df_scaled['high'] <= upper_limit) &
                    (df_scaled['low'] >= lower_limit) & (df_scaled['low'] <= upper_limit) &
                    (df_scaled['close'] >= lower_limit) & (df_scaled['close'] <= upper_limit)
                )
            else:
                # ===== CASH/FUTURE DATA LOGIC (SPOT/FUTURE) =====
                print("DEBUG: Applying CASH/FUTURE data filtering logic")
                
                # For cash/future data, all values should be in thousands range
                valid_mask = (
                    (df_scaled['open'] >= 1000) & (df_scaled['open'] <= 100000) &
                    (df_scaled['high'] >= 1000) & (df_scaled['high'] <= 100000) &
                    (df_scaled['low'] >= 1000) & (df_scaled['low'] <= 100000) &
                    (df_scaled['close'] >= 1000) & (df_scaled['close'] <= 100000)
                )
                print("DEBUG: Using cash/future range (1000-100000)")
            
            df_scaled = df_scaled[valid_mask]
            print(f"DEBUG: Filtered mixed data - kept {len(df_scaled)} records out of original")
            
            if len(df_scaled) == 0:
                print("ERROR: No valid data after filtering mixed values")
                return None
        
        try:
            # For options data, use more careful resampling to avoid picking wrong values
            if data_type in ['nifty_call', 'nifty_put', 'banknifty_call', 'banknifty_put', 'midcpnifty_call', 'midcpnifty_put', 'sensex_call', 'sensex_put']:
                print("DEBUG: Using options-specific resampling logic")
                # Filter out obviously wrong values (like 1) before resampling
                df_clean = df_scaled.copy()
                # Remove records where all OHLC values are 1 (likely data errors)
                invalid_mask = (df_clean['open'] == 1) & (df_clean['high'] == 1) & (df_clean['low'] == 1) & (df_clean['close'] == 1)
                df_clean = df_clean[~invalid_mask]
                print(f"DEBUG: Removed {invalid_mask.sum()} invalid records (all values = 1)")
                
                resampled = df_clean.resample(f'{interval_minutes}min').agg({
                    'open': 'first',
                    'high': 'max',
                    'low': 'min',
                    'close': 'last'
                }).dropna()
                print(f"DEBUG: Options resampling successful: {len(resampled)} records")
            else:
                # Use standard resampling for cash/future data
                resampled = df_scaled.resample(f'{interval_minutes}min').agg({
                    'open': 'first',
                    'high': 'max',
                    'low': 'min',
                    'close': 'last'
                }).dropna()
                print(f"DEBUG: Standard resampling successful: {len(resampled)} records")
        except Exception as e:
            print(f"DEBUG: Resampling failed: {e}")
            # Fallback: manual resampling with simple aggregation
            df_scaled['time_group'] = df_scaled.index.floor(f'{interval_minutes}min')
            
            def simple_group_agg(group):
                result = {}
                for col in ['open', 'high', 'low', 'close']:
                    if col in group.columns:
                        if col == 'open':
                            result[col] = group[col].iloc[0]
                        elif col == 'high':
                            result[col] = group[col].max()
                        elif col == 'low':
                            result[col] = group[col].min()
                        elif col == 'close':
                            result[col] = group[col].iloc[-1]
                return pd.Series(result)
            
            resampled = df_scaled.groupby('time_group').apply(simple_group_agg).dropna()
            print(f"DEBUG: Manual resampling successful: {len(resampled)} records")
        
        # After resampling, filter out any remaining mixed data
        if len(resampled) > 0:
            # Separate filtering logic for options vs cash/future data
            if data_type in ['nifty_call', 'nifty_put', 'banknifty_call', 'banknifty_put', 'midcpnifty_call', 'midcpnifty_put', 'sensex_call', 'sensex_put']:
                # ===== OPTIONS DATA LOGIC (CALL/PUT) =====
                print("DEBUG: Applying OPTIONS data filtering after resampling")
                print(f"DEBUG: Before filtering - resampled values:")
                print(f"  Open: {resampled['open'].head().tolist()}")
                print(f"  High: {resampled['high'].head().tolist()}")
                print(f"  Low: {resampled['low'].head().tolist()}")
                print(f"  Close: {resampled['close'].head().tolist()}")
                
                # For options data, use flexible thresholds based on actual values
                all_resampled_values = pd.concat([resampled['open'], resampled['high'], resampled['low'], resampled['close']])
                min_resampled = all_resampled_values.min()
                max_resampled = all_resampled_values.max()
                
                print(f"DEBUG: Resampled options range - min: {min_resampled}, max: {max_resampled}")
                
                if max_resampled > 1000 and min_resampled > 100:  # All values are large (like call data)
                    # For large option values, use broader range
                    lower_limit = 0.01
                    upper_limit = max(10000, max_resampled * 1.5)
                    print(f"DEBUG: Using large resampled options range ({lower_limit} to {upper_limit})")
                elif max_resampled < 1000 and min_resampled > 0.1:  # All values are small (like put data)
                    # For small option values, use normal range
                    lower_limit = 0.01
                    upper_limit = 1000
                    print(f"DEBUG: Using small resampled options range ({lower_limit} to {upper_limit})")
                else:
                    # Mixed data or edge cases - use very permissive range
                    lower_limit = 0.01
                    upper_limit = max(10000, max_resampled * 2)  # Very permissive
                    print(f"DEBUG: Using mixed/permissive resampled options range ({lower_limit} to {upper_limit})")
                
                valid_mask = (
                    (resampled['open'] >= lower_limit) & (resampled['open'] <= upper_limit) &
                    (resampled['high'] >= lower_limit) & (resampled['high'] <= upper_limit) &
                    (resampled['low'] >= lower_limit) & (resampled['low'] <= upper_limit) &
                    (resampled['close'] >= lower_limit) & (resampled['close'] <= upper_limit)
                )
                resampled = resampled[valid_mask]
                print(f"DEBUG: After filtering options resampled data - kept {len(resampled)} records")
                print(f"DEBUG: After filtering - resampled values:")
                print(f"  Open: {resampled['open'].head().tolist()}")
                print(f"  High: {resampled['high'].head().tolist()}")
                print(f"  Low: {resampled['low'].head().tolist()}")
                print(f"  Close: {resampled['close'].head().tolist()}")
            else:
                # ===== CASH/FUTURE DATA LOGIC (SPOT/FUTURE) =====
                print("DEBUG: Applying CASH/FUTURE data filtering after resampling")
                # Check for mixed data in resampled results
                has_large_values = (resampled['open'] > 1000).any() or (resampled['high'] > 1000).any()
                has_small_values = (resampled['low'] < 100).any() or (resampled['close'] < 100).any()
                
                if has_large_values and has_small_values:
                    print("WARNING: Mixed data detected in resampled results - filtering out small values")
                    # Keep only records where all values are in the thousands range
                    valid_mask = (
                        (resampled['open'] >= 1000) & (resampled['open'] <= 100000) &
                        (resampled['high'] >= 1000) & (resampled['high'] <= 100000) &
                        (resampled['low'] >= 1000) & (resampled['low'] <= 100000) &
                        (resampled['close'] >= 1000) & (resampled['close'] <= 100000)
                    )
                    resampled = resampled[valid_mask]
                    print(f"DEBUG: After filtering mixed resampled data - kept {len(resampled)} records")
        
        # Debug: Print resampled values
        if len(resampled) > 0:
            print(f"DEBUG: Resampled OHLC values (first 5 rows):")
            print(f"  Open: {resampled['open'].head().tolist()}")
            print(f"  High: {resampled['high'].head().tolist()}")
            print(f"  Low: {resampled['low'].head().tolist()}")
            print(f"  Close: {resampled['close'].head().tolist()}")
            
            # Debug: Check for 12:05:00 specifically
            if 'time_readable' in resampled.columns:
                time_12_05 = resampled[resampled['time_readable'] == '12:05']
                if len(time_12_05) > 0:
                    row = time_12_05.iloc[0]
                    print(f"DEBUG: 12:05:00 specific values:")
                    print(f"  Open: {row['open']}")
                    print(f"  High: {row['high']}")
                    print(f"  Low: {row['low']}")
                    print(f"  Close: {row['close']}")
                else:
                    print("DEBUG: No 12:05:00 data found in resampled data")
        
        if len(resampled) == 0:
            print("DEBUG: No data after resampling!")
            return None
            
        # Reset index to get datetime as a column
        resampled.reset_index(inplace=True)
        
        # Format time for display
        # Check what the datetime column is named after reset_index
        datetime_col = None
        for col in resampled.columns:
            if 'datetime' in col.lower() or resampled[col].dtype.name.startswith('datetime'):
                datetime_col = col
                break
        
        if datetime_col is None:
            print(f"DEBUG: Available columns after reset_index: {list(resampled.columns)}")
            print("ERROR: Could not find datetime column after resampling")
            return None
        
        print(f"DEBUG: Using datetime column: {datetime_col}")
        
        resampled['time_readable'] = resampled[datetime_col].dt.strftime('%H:%M')
        resampled['date_readable'] = resampled[datetime_col].dt.strftime('%Y-%m-%d')
        
        # Add the missing 'time' column (seconds since midnight) for calculate_time_frame function
        resampled['time'] = resampled[datetime_col].dt.hour * 3600 + resampled[datetime_col].dt.minute * 60
        
        print(f"DEBUG: Resampled time range: {resampled['time_readable'].iloc[0]} to {resampled['time_readable'].iloc[-1]}")
        print(f"DEBUG: Sample times: {resampled['time_readable'].head(5).tolist()}")
        print(f"DEBUG: Added 'time' column with values: {resampled['time'].head(5).tolist()}")
        
        return resampled
        
    except Exception as e:
        print(f"Error resampling data: {e}")
        import traceback
        traceback.print_exc()
        return None

def resample_straddle_data(df, interval_minutes):
    """Resample straddle data to specified interval"""
    if df is None or len(df) == 0:
        return None
    
    try:
        print(f"DEBUG: Resampling straddle data {len(df)} records to {interval_minutes}-minute intervals")
        
        # Create datetime index for resampling
        df['datetime'] = pd.to_datetime(df['date_readable'] + ' ' + df['time_readable'])
        df.set_index('datetime', inplace=True)
        
        print(f"DEBUG: Original time range: {df.index[0]} to {df.index[-1]}")
        
        # Resample data to specified interval
        print(f"DEBUG: Using resampling rule: '{interval_minutes}min'")
        try:
            # First try the standard approach
            resampled = df.resample(f'{interval_minutes}min').agg({
                'straddle_open': 'first',
                'straddle_high': 'max',
                'straddle_low': 'min',
                'straddle_close': 'last',
                'call_open': 'first',
                'call_high': 'max',
                'call_low': 'min',
                'call_close': 'last',
                'put_open': 'first',
                'put_high': 'max',
                'put_low': 'min',
                'put_close': 'last'
            }).dropna()
            print(f"DEBUG: Standard resampling successful: {len(resampled)} records")
        except Exception as e:
            print(f"DEBUG: Standard resampling failed: {e}")
            # Fallback: manual resampling
            df['time_group'] = df.index.floor(f'{interval_minutes}min')
            resampled = df.groupby('time_group').agg({
                'straddle_open': 'first',
                'straddle_high': 'max',
                'straddle_low': 'min',
                'straddle_close': 'last',
                'call_open': 'first',
                'call_high': 'max',
                'call_low': 'min',
                'call_close': 'last',
                'put_open': 'first',
                'put_high': 'max',
                'put_low': 'min',
                'put_close': 'last'
            }).dropna()
            print(f"DEBUG: Manual resampling successful: {len(resampled)} records")
        
        if len(resampled) == 0:
            print("DEBUG: No data after resampling!")
            return None
            
        # Reset index to get datetime as a column
        resampled.reset_index(inplace=True)
        
        # Format time for display
        # Check what the datetime column is named after reset_index
        datetime_col = None
        for col in resampled.columns:
            if 'datetime' in col.lower() or resampled[col].dtype.name.startswith('datetime'):
                datetime_col = col
                break
        
        if datetime_col is None:
            print(f"DEBUG: Available columns after reset_index: {list(resampled.columns)}")
            print("ERROR: Could not find datetime column after resampling")
            return None
        
        print(f"DEBUG: Using datetime column: {datetime_col}")
        
        resampled['time_readable'] = resampled[datetime_col].dt.strftime('%H:%M')
        resampled['date_readable'] = resampled[datetime_col].dt.strftime('%Y-%m-%d')
        
        # Add the missing 'time' column (seconds since midnight) for calculate_time_frame function
        resampled['time'] = resampled[datetime_col].dt.hour * 3600 + resampled[datetime_col].dt.minute * 60
        
        print(f"DEBUG: Resampled time range: {resampled['time_readable'].iloc[0]} to {resampled['time_readable'].iloc[-1]}")
        print(f"DEBUG: Sample times: {resampled['time_readable'].head(5).tolist()}")
        print(f"DEBUG: Added 'time' column with values: {resampled['time'].head(5).tolist()}")
        
        return resampled
        
    except Exception as e:
        print(f"Error resampling straddle data: {e}")
        import traceback
        traceback.print_exc()
        return None

def create_candlestick_chart_base64(df, date, interval_minutes, data_type, symbol='nifty', indicators=None):
    """Create a professional candlestick chart and return as base64 string"""
    if df is None or len(df) == 0:
        return None
    
    # Create datetime index for proper time series plotting
    df['datetime'] = pd.to_datetime(df['date_readable'] + ' ' + df['time_readable'])
    df.set_index('datetime', inplace=True)
    
    # Data is already scaled from resampling function
    df_scaled = df.copy()
    
    # Set dark theme style
    plt.style.use('dark_background')
    
    # Set up the plot with dark theme
    fig, ax = plt.subplots(figsize=(16, 9), facecolor='#1a1a1a')
    ax.set_facecolor('#1a1a1a')
    
    # Color scheme based on data type
    color_schemes = {
        'nifty_cash': {'bull': '#00ff88', 'bear': '#ff4444', 'edge_bull': '#00cc66', 'edge_bear': '#cc3333'},
        'nifty_future': {'bull': '#00ff88', 'bear': '#ff4444', 'edge_bull': '#00cc66', 'edge_bear': '#cc3333'},
        'nifty_call': {'bull': '#00ff88', 'bear': '#ff4444', 'edge_bull': '#00cc66', 'edge_bear': '#cc3333'},
        'nifty_put': {'bull': '#00ff88', 'bear': '#ff4444', 'edge_bull': '#00cc66', 'edge_bear': '#cc3333'}
    }
    
    colors = color_schemes.get(data_type, color_schemes['nifty_cash'])
    
    # Debug: Print values being used in chart
    print(f"DEBUG: Chart values (first 5 rows):")
    for i, (idx, row) in enumerate(df_scaled.head().iterrows()):
        print(f"  Row {i}: Open={row['open']}, High={row['high']}, Low={row['low']}, Close={row['close']}")
    
    # Debug: Check for contaminated data in the entire dataset
    print(f"DEBUG: Checking for contaminated data in entire dataset:")
    
    # Use flexible thresholds based on actual data values
    all_values = pd.concat([df_scaled['open'], df_scaled['high'], df_scaled['low'], df_scaled['close']])
    min_val = all_values.min()
    max_val = all_values.max()
    
    print(f"  Data range - min: {min_val}, max: {max_val}")
    
    if data_type in ['nifty_call', 'nifty_put', 'banknifty_call', 'banknifty_put', 'midcpnifty_call', 'midcpnifty_put', 'sensex_call', 'sensex_put']:
        # For options data, use flexible range based on actual values
        if max_val > 1000 and min_val > 100:  # All values are large (like call data)
            min_price_threshold = 0.01
            max_price_threshold = max(10000, max_val * 1.5)
            print(f"  Using large options thresholds: {min_price_threshold} to {max_price_threshold}")
        elif max_val < 1000 and min_val > 0.1:  # All values are small (like put data)
            min_price_threshold = 0.01
            max_price_threshold = 1000
            print(f"  Using small options thresholds: {min_price_threshold} to {max_price_threshold}")
        else:
            # Mixed data or edge cases - use very permissive range
            min_price_threshold = 0.01
            max_price_threshold = max(10000, max_val * 2)  # Very permissive
            print(f"  Using mixed/permissive options thresholds: {min_price_threshold} to {max_price_threshold}")
    else:
        # For cash/future data, use higher thresholds
        min_price_threshold = 1000
        max_price_threshold = 1000000
        print(f"  Using cash/future thresholds: {min_price_threshold} to {max_price_threshold}")
    
    # Filter out contaminated data before plotting
    print(f"DEBUG: Filtering contaminated data before plotting...")
    original_count = len(df_scaled)
    df_scaled = df_scaled[(df_scaled['low'] >= min_price_threshold) & (df_scaled['close'] >= min_price_threshold) & 
                         (df_scaled['low'] <= max_price_threshold) & (df_scaled['close'] <= max_price_threshold)]
    filtered_count = len(df_scaled)
    print(f"  Original records: {original_count}, After filtering: {filtered_count}")
    
    if len(df_scaled) == 0:
        print("ERROR: No valid data left after filtering contaminated values")
        return None
    
    # Plot candlesticks
    print(f"DEBUG: Plotting {len(df_scaled)} candlesticks...")
    for i, (idx, row) in enumerate(df_scaled.iterrows()):
        open_price = row['open']
        close_price = row['close']
        high_price = row['high']
        low_price = row['low']
        
        # Debug: Print first few candlestick dimensions
        if i < 5:
            print(f"  Candlestick {i}: O={open_price:.2f}, H={high_price:.2f}, L={low_price:.2f}, C={close_price:.2f}")
            print(f"    Body height: {abs(close_price - open_price):.2f}, Body bottom: {min(open_price, close_price):.2f}")
            print(f"    Wick range: {low_price:.2f} to {high_price:.2f}")
        
        if close_price >= open_price:
            color = colors['bull']
            edge_color = colors['edge_bull']
            wick_color = colors['bull']
        else:
            color = colors['bear']
            edge_color = colors['edge_bear']
            wick_color = colors['bear']
        
        # Plot the wick (vertical line from low to high)
        ax.plot([i, i], [low_price, high_price], color=wick_color, linewidth=3, alpha=0.9, solid_capstyle='round')
        
        # Plot the body
        body_height = abs(close_price - open_price)
        body_bottom = min(open_price, close_price)
        
        if body_height > 0:
            # Use rectangle for better visibility
            from matplotlib.patches import Rectangle
            rect = Rectangle((i - 0.3, body_bottom), 0.6, body_height, 
                           facecolor=color, edgecolor=edge_color, linewidth=2, alpha=0.9)
            ax.add_patch(rect)
        else:
            # Doji (when open = close) - horizontal line
            ax.plot([i-0.3, i+0.3], [open_price, open_price], color=edge_color, linewidth=4, alpha=0.9)
    
            # Customize the plot with user-friendly names
        display_names = {
            'nifty_cash': 'Spot',
            'nifty_future': 'Future',
            'nifty_call': 'Call',
            'nifty_put': 'Put'
        }
        data_type_display = display_names.get(data_type, data_type.replace('_', ' ').title())
        
        symbol_display = symbol.upper() # For displaying NIFTY or BANKNIFTY
        
        if interval_minutes == 1:
            title = f'{symbol_display} Index • OHLC Candlestick Chart ({date}) - {data_type_display}'
        else:
            title = f'{symbol_display} Index • {interval_minutes}-Minute OHLC Candlestick Chart ({date}) - {data_type_display}'
    
    ax.set_title(title, fontsize=18, fontweight='bold', color='#ffffff', pad=20)
    ax.set_xlabel('Time', fontsize=14, color='#cccccc', fontweight='bold')
    ax.set_ylabel('Price (INR)', fontsize=14, color='#cccccc', fontweight='bold')
    
    # Grid and styling
    ax.grid(True, alpha=0.2, color='#444444', linewidth=0.8)
    ax.set_axisbelow(True)
    
    # Set x-axis labels
    n_points = len(df)
    if n_points > 20:
        step = max(1, n_points // 15)
        x_ticks = range(0, n_points, step)
        x_labels = [df.index[i].strftime('%H:%M') for i in x_ticks]
    else:
        x_ticks = range(n_points)
        x_labels = [df.index[i].strftime('%H:%M') for i in x_ticks]
    
    ax.set_xticks(x_ticks)
    ax.set_xticklabels(x_labels, rotation=45, color='#cccccc', fontsize=11)
    
    # Set y-axis styling
    ax.tick_params(axis='y', colors='#cccccc', labelsize=11)
    
    # Adjust y-axis limits to show proper candlestick range
    if len(df_scaled) > 0:
        all_prices = []
        for _, row in df_scaled.iterrows():
            all_prices.extend([row['open'], row['high'], row['low'], row['close']])
        
        if all_prices:
            min_price = min(all_prices)
            max_price = max(all_prices)
            price_range = max_price - min_price
            
            # Add some padding and ensure minimum range for visibility
            # For options data, use smaller padding since prices are typically small
            if data_type in ['nifty_call', 'nifty_put', 'banknifty_call', 'banknifty_put', 'midcpnifty_call', 'midcpnifty_put', 'sensex_call', 'sensex_put']:
                padding = max(price_range * 0.1, 0.5)  # 10% padding or minimum 0.5 points for options
            else:
                padding = max(price_range * 0.1, 50)  # 10% padding or minimum 50 points for cash/future
            y_min = min_price - padding
            y_max = max_price + padding
            
            ax.set_ylim(y_min, y_max)
            print(f"DEBUG: Set y-axis limits: {y_min:.2f} to {y_max:.2f} (range: {price_range:.2f})")
    
    # Add price statistics box
    current_price = df_scaled['close'].iloc[-1]
    price_change = current_price - df_scaled['open'].iloc[0]
    price_change_pct = (price_change / df_scaled['open'].iloc[0]) * 100
    
    stats_text = f"""O {df_scaled['open'].iloc[0]:,.2f}
H {df_scaled['high'].max():,.2f}
L {df_scaled['low'].min():,.2f}
C {current_price:,.2f}
{price_change:+.2f} ({price_change_pct:+.2f}%)"""
    
    bbox_props = dict(boxstyle='round,pad=0.8', facecolor='#2a2a2a', 
                      edgecolor='#444444', alpha=0.9)
    
    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, 
            verticalalignment='top', fontsize=12, fontweight='bold',
            color='#ffffff', bbox=bbox_props, fontfamily='monospace')
    
    # Add current price line indicator
    ax.axhline(y=current_price, color='#ff4444', linestyle='--', alpha=0.7, linewidth=1.5)
    
    # Style the spines
    for spine in ax.spines.values():
        spine.set_color('#444444')
        spine.set_linewidth(1.5)
    
    # Plot indicators if specified
    print(f"=== INDICATORS DEBUG ===")
    print(f"Indicators received: {indicators}")
    print(f"Indicators type: {type(indicators)}")
    
    if indicators:
        print(f"Processing {len(indicators)} indicators")
        for indicator in indicators:
            print(f"Processing indicator: {indicator}")
            if indicator == 'vwap':
                print("VWAP indicator detected, calculating...")
                vwap_values = calculate_vwap_regular(df)
                print(f"VWAP values returned: {vwap_values is not None}")
                if vwap_values is not None:
                    print(f"Plotting VWAP line with {len(vwap_values)} points")
                    ax.plot(range(len(vwap_values)), vwap_values, color='#ff6b6b', linewidth=2, 
                           label='VWAP', alpha=0.8)
                    print("VWAP line plotted successfully")
                else:
                    print("VWAP values are None, not plotting")
            elif indicator == 'ema_20':
                print("EMA 20 indicator detected, calculating...")
                ema_20_values = calculate_ema(df, period=20, price_column='close')
                print(f"EMA 20 values returned: {ema_20_values is not None}")
                if ema_20_values is not None:
                    print(f"Plotting EMA 20 line with {len(ema_20_values)} points")
                    ax.plot(range(len(ema_20_values)), ema_20_values, color='#ff6b35', linewidth=2, 
                           label='EMA (Close, 20)', alpha=0.8)
                    print("EMA 20 line plotted successfully")
                else:
                    print("EMA 20 values are None, not plotting")
            
            elif indicator == 'ema_50':
                print("EMA 50 indicator detected, calculating...")
                ema_50_values = calculate_ema(df, period=50, price_column='close')
                print(f"EMA 50 values returned: {ema_50_values is not None}")
                if ema_50_values is not None:
                    print(f"Plotting EMA 50 line with {len(ema_50_values)} points")
                    ax.plot(range(len(ema_50_values)), ema_50_values, color='#4ecdc4', linewidth=2, 
                           label='EMA (Close, 50)', alpha=0.8)
                    print("EMA 50 line plotted successfully")
                else:
                    print("EMA 50 values are None, not plotting")
            
            elif indicator == 'ema_100':
                print("EMA 100 indicator detected, calculating...")
                ema_100_values = calculate_ema(df, period=100, price_column='close')
                print(f"EMA 100 values returned: {ema_100_values is not None}")
                if ema_100_values is not None:
                    print(f"Plotting EMA 100 line with {len(ema_100_values)} points")
                    ax.plot(range(len(ema_100_values)), ema_100_values, color='#9b59b6', linewidth=2, 
                           label='EMA (Close, 100)', alpha=0.8)
                    print("EMA 100 line plotted successfully")
                else:
                    print("EMA 100 values are None, not plotting")
            
            elif indicator == 'ema_200':
                print("EMA 200 indicator detected, calculating...")
                ema_200_values = calculate_ema(df, period=200, price_column='close')
                print(f"EMA 200 values returned: {ema_200_values is not None}")
                if ema_200_values is not None:
                    print(f"Plotting EMA 200 line with {len(ema_200_values)} points")
                    ax.plot(range(len(ema_200_values)), ema_200_values, color='#e74c3c', linewidth=2, 
                           label='EMA (Close, 200)', alpha=0.8)
                    print("EMA 200 line plotted successfully")
                else:
                    print("EMA 200 values are None, not plotting")
            else:
                print(f"Unknown indicator: {indicator}")
        
        # Add legend for indicators
        ax.legend(loc='upper left', fontsize=10, framealpha=0.8, 
                 facecolor='#2a2a2a', edgecolor='#444444')
        print("Legend added for indicators")
    else:
        print("No indicators received")
    
    plt.tight_layout()
    
    # Convert plot to base64 string
    img_buffer = io.BytesIO()
    try:
        plt.savefig(img_buffer, format='png', dpi=300, bbox_inches='tight', 
                    facecolor='#1a1a1a', edgecolor='none')
        img_buffer.seek(0)
        img_base64 = base64.b64encode(img_buffer.getvalue()).decode()
    except Exception as e:
        print(f"Error saving chart: {e}")
        return None
    finally:
        plt.close('all')
        plt.clf()
    
    return img_base64

def create_summary_chart_base64(df, date, data_type, symbol='nifty'):
    """Create a professional summary chart and return as base64 string"""
    if df is None or len(df) == 0:
        return None
    
    # Scale down OHLC values
    df_scaled = df.copy()
    df_scaled['open'] = df['open'] / 100
    df_scaled['high'] = df['high'] / 100
    df_scaled['low'] = df['low'] / 100
    df_scaled['close'] = df['close'] / 100
    
    # Calculate daily OHLC
    daily_open = df_scaled['open'].iloc[0]
    daily_high = df_scaled['high'].max()
    daily_low = df_scaled['low'].min()
    daily_close = df_scaled['close'].iloc[-1]
    
    # Set dark theme style
    plt.style.use('dark_background')
    
    # Create the plot with dark theme
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 12), facecolor='#1a1a1a')
    fig.patch.set_facecolor('#1a1a1a')
    
    # Color scheme based on data type
    color_schemes = {
        'nifty_cash': {'line': '#00ff88', 'fill': '#00ff88', 'open': '#00ff88', 'close': '#ff4444'},
        'nifty_future': {'line': '#00ccff', 'fill': '#00ccff', 'open': '#00ff88', 'close': '#ff4444'},
        'nifty_call': {'line': '#00ff88', 'fill': '#00ff88', 'open': '#00ff88', 'close': '#ff4444'},
        'nifty_put': {'line': '#ff8800', 'fill': '#ff8800', 'open': '#00ff88', 'close': '#ff4444'}
    }
    
    colors = color_schemes.get(data_type, color_schemes['nifty_cash'])
    
    # Set background for both subplots
    ax1.set_facecolor('#1a1a1a')
    ax2.set_facecolor('#1a1a1a')
    
    # Plot 1: Price movement
    df_scaled['datetime'] = pd.to_datetime(df['date_readable'] + ' ' + df['time_readable'])
    df_scaled.set_index('datetime', inplace=True)
    
    # Use user-friendly names for labels and title
    display_names = {
        'nifty_cash': 'Spot',
        'nifty_future': 'Future',
        'nifty_call': 'Call',
        'nifty_put': 'Put',
        'banknifty_cash': 'Spot',
        'banknifty_future': 'Future',
        'banknifty_call': 'Call',
        'banknifty_put': 'Put'
    }
    data_type_display = display_names.get(data_type, data_type.replace('_', ' ').title())
    
    symbol_display = symbol.upper() # For displaying NIFTY or BANKNIFTY
    
    ax1.plot(df_scaled.index, df_scaled['close'], label=f'{data_type_display} Close Price',
            linewidth=3, color=colors['line'], alpha=0.9)
    
    ax1.fill_between(df_scaled.index, df_scaled['low'], df_scaled['high'], alpha=0.2, color=colors['fill'], label='High-Low Range')
    ax1.axhline(y=daily_open, color=colors['open'], linestyle='--', linewidth=2, alpha=0.8, 
                label=f'Open: {daily_open:,.2f}')
    ax1.axhline(y=daily_close, color=colors['close'], linestyle='--', linewidth=2, alpha=0.8, 
                label=f'Close: {daily_close:,.2f}')
    
    title = f'{symbol_display} Index • Daily Price Movement ({date}) - {data_type_display}'
    
    ax1.set_title(title, fontsize=16, fontweight='bold', color='#ffffff', pad=20)
    ax1.set_ylabel('Price (INR)', fontsize=13, color='#cccccc', fontweight='bold')
    ax1.legend(framealpha=0.9, facecolor='#2a2a2a', edgecolor='#444444')
    ax1.grid(True, alpha=0.2, color='#444444', linewidth=0.8)
    ax1.set_axisbelow(True)
    
    # Format x-axis
    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))
    ax1.xaxis.set_major_locator(mdates.MinuteLocator(interval=30))
    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, color='#cccccc', fontsize=10)
    ax1.tick_params(axis='y', colors='#cccccc', labelsize=10)
    
    # Plot 2: OHLC Bar Chart
    categories = ['Open', 'High', 'Low', 'Close']
    values = [daily_open, daily_high, daily_low, daily_close]
    bar_colors = [colors['open'], colors['line'], '#ffaa00', colors['close']]
    
    bars = ax2.bar(categories, values, color=bar_colors, alpha=0.8, edgecolor='#444444', linewidth=1.5)
    ax2.set_title(f'Daily OHLC Summary - {data_type_display}', fontsize=16, fontweight='bold', color='#ffffff', pad=20)
    ax2.set_ylabel('Price (INR)', fontsize=13, color='#cccccc', fontweight='bold')
    ax2.grid(True, alpha=0.2, color='#444444', linewidth=0.8)
    ax2.set_axisbelow(True)
    
    # Add value labels on bars
    for bar, value in zip(bars, values):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                f'{value:,.2f}', ha='center', va='bottom', fontweight='bold', 
                color='#ffffff', fontsize=11)
    
    # Add price change information
    price_change = daily_close - daily_open
    price_change_pct = (price_change / daily_open) * 100
    change_color = '#00ff88' if price_change >= 0 else '#ff4444'
    
    change_text = f"Change: {price_change:+,.2f} ({price_change_pct:+.2f}%)"
    bbox_props = dict(boxstyle='round,pad=0.8', facecolor='#2a2a2a', 
                      edgecolor='#444444', alpha=0.9)
    
    ax2.text(0.5, 0.95, change_text, transform=ax2.transAxes, 
             ha='center', va='top', fontsize=12, fontweight='bold',
             bbox=bbox_props, color='#ffffff')
    
    # Style the spines for both subplots
    for ax in [ax1, ax2]:
        for spine in ax.spines.values():
            spine.set_color('#444444')
            spine.set_linewidth(1.5)
    
    plt.tight_layout()
    
    # Convert plot to base64 string
    img_buffer = io.BytesIO()
    try:
        plt.savefig(img_buffer, format='png', dpi=300, bbox_inches='tight', 
                    facecolor='#1a1a1a', edgecolor='none')
        img_buffer.seek(0)
        img_base64 = base64.b64encode(img_buffer.getvalue()).decode()
    except Exception as e:
        print(f"Error saving summary chart: {e}")
        return None
    finally:
        plt.close('all')
        plt.clf()
    
    return img_base64

@app.route('/')
def main_index():
    """Main landing page with chart type selection"""
    return render_template('main_index.html')

@app.route('/symbol_selection')
def symbol_selection():
    """Symbol selection page for single chart analysis"""
    return render_template('symbol_selection.html')

@app.route('/single_chart')
def single_chart():
    """Single chart analysis page with data type selection and date selection"""
    symbol = request.args.get('symbol', 'nifty')
    data_type = request.args.get('data_type', '')
    
    print(f"=== SINGLE CHART DEBUG ===")
    print(f"  Requested symbol: {symbol}")
    print(f"  Requested data_type: {data_type}")
    
    # Determine data types based on symbol
    if symbol == 'nifty':
        data_types = ['nifty_cash', 'nifty_future', 'nifty_call', 'nifty_put']
        if not data_type or not data_type.startswith('nifty_'):
            data_type = 'nifty_cash'
    elif symbol == 'banknifty':
        data_types = ['banknifty_cash', 'banknifty_future', 'banknifty_call', 'banknifty_put']
        if not data_type or not data_type.startswith('banknifty_'):
            data_type = 'banknifty_cash'
    elif symbol == 'midcpnifty':
        data_types = ['midcpnifty_cash', 'midcpnifty_future', 'midcpnifty_call', 'midcpnifty_put']
        if not data_type or not data_type.startswith('midcpnifty_'):
            data_type = 'midcpnifty_cash'
    elif symbol == 'sensex':
        data_types = ['sensex_cash', 'sensex_future', 'sensex_call', 'sensex_put']
        if not data_type or not data_type.startswith('sensex_'):
            data_type = 'sensex_cash'
    else:
        # Default to nifty
        symbol = 'nifty'
        data_types = ['nifty_cash', 'nifty_future', 'nifty_call', 'nifty_put']
        data_type = 'nifty_cash'
    
    print(f"  Final symbol: {symbol}")
    print(f"  Final data_types: {data_types}")
    print(f"  Final selected_data_type: {data_type}")
    
    return render_template('all_index.html', 
                         symbol=symbol,
                         selected_symbol=symbol,
                         data_types=data_types,
                         selected_data_type=data_type)

@app.route('/change_data_type')
def change_data_type():
    """Change data type and redirect to single chart page"""
    symbol = request.args.get('symbol', 'nifty')
    data_type = request.args.get('data_type', 'nifty_cash')
    return redirect(url_for('single_chart', symbol=symbol, data_type=data_type))

@app.route('/generate_chart', methods=['POST'])
def generate_chart():
    """Generate chart based on selected parameters"""
    date = request.form.get('date')
    chart_type = request.form.get('chart_type')
    timeframe = request.form.get('timeframe', '1')
    data_type = request.form.get('data_type', 'nifty_cash')
    strike = request.form.get('strike')
    expiry = request.form.get('expiry')
    
    # Get indicators from form data
    indicators = request.form.getlist('indicators') if request.form.get('indicators') else []
    print(f"=== ROUTE DEBUG ===")
    print(f"Form data indicators: {request.form.getlist('indicators')}")
    print(f"Form data indicators (get): {request.form.get('indicators')}")
    print(f"Final indicators list: {indicators}")
    print(f"Indicators type: {type(indicators)}")
    print(f"Indicators length: {len(indicators)}")
    
    # Get symbol from form data, fallback to determining from data type
    symbol = request.form.get('symbol', '')
    if not symbol:
        if data_type.startswith('banknifty_'):
            symbol = 'banknifty'
        elif data_type.startswith('midcpnifty_'):
            symbol = 'midcpnifty'
        elif data_type.startswith('sensex_'):
            symbol = 'sensex'
        else:
            symbol = 'nifty'
    
    print(f"=== CHART GENERATION DEBUG ===")
    print(f"Received parameters:")
    print(f"  date: {date}")
    print(f"  chart_type: {chart_type}")
    print(f"  timeframe: '{timeframe}' (type: {type(timeframe)})")
    print(f"  data_type: {data_type}")
    print(f"  strike: {strike}")
    print(f"  expiry: {expiry}")

    
    if not date:
        return jsonify({'error': 'Please select a date'})
    
    # For options, validate strike and expiry
    if data_type in ['nifty_call', 'nifty_put', 'banknifty_call', 'banknifty_put', 'midcpnifty_call', 'midcpnifty_put', 'sensex_call', 'sensex_put']:
        if not strike:
            return jsonify({'error': 'Please select a strike price for options'})
        if not expiry:
            return jsonify({'error': 'Please select an expiry date for options'})
    
    # Convert timeframe to integer
    try:
        interval_minutes = int(timeframe)
        print(f"Converted timeframe '{timeframe}' to interval_minutes: {interval_minutes}")
    except ValueError:
        interval_minutes = 1
        print(f"Failed to convert timeframe '{timeframe}', using default: {interval_minutes}")
    
    df = get_ohlc_data_for_date(date, data_type, strike, expiry, symbol)
    if df is None:
        error_msg = f'No data found for date: {date} and data type: {data_type}'
        if data_type in ['nifty_call', 'nifty_put'] or data_type in ['banknifty_call', 'banknifty_put']:
            error_msg += f', strike: {strike}, expiry: {expiry}'
        return jsonify({'error': error_msg})
    
    if chart_type == 'candlestick':
        print(f"Processing candlestick chart with interval_minutes: {interval_minutes}")
        
        # Resample data to selected timeframe
        df_resampled = resample_ohlc_data(df, interval_minutes, data_type)
        if df_resampled is None:
            return jsonify({'error': 'Failed to resample data for selected timeframe'})
        
        print(f"Resampling completed. Original records: {len(df)}, Resampled records: {len(df_resampled)}")
        
        chart_base64 = create_candlestick_chart_base64(df_resampled, date, interval_minutes, data_type, symbol, indicators)
        if chart_base64 is None:
            return jsonify({'error': 'Failed to generate candlestick chart'})
            
        # Use user-friendly names for chart titles
        display_names = {
            'nifty_cash': 'Spot',
            'nifty_future': 'Future',
            'nifty_call': 'Call',
            'nifty_put': 'Put',
            'banknifty_cash': 'Spot',
            'banknifty_future': 'Future',
            'banknifty_call': 'Call',
            'banknifty_put': 'Put',
            'midcpnifty_cash': 'Spot',
            'midcpnifty_future': 'Future',
            'midcpnifty_call': 'Call',
            'midcpnifty_put': 'Put',
            'sensex_cash': 'Spot',
            'sensex_future': 'Future',
            'sensex_call': 'Call',
            'sensex_put': 'Put'
        }
        data_type_display = display_names.get(data_type, data_type.replace('_', ' ').title())
        if interval_minutes == 1:
            chart_title = f'Candlestick Chart - {date} ({data_type_display})'
        else:
            chart_title = f'{interval_minutes}-Minute Candlestick Chart - {date} ({data_type_display})'
        
        print(f"Generated chart title: '{chart_title}'")
        
        # Filter out contaminated data before preparing interactive chart data
        print(f"DEBUG: Filtering contaminated data for interactive chart...")
        original_count = len(df_resampled)
        
        # Use flexible thresholds based on actual data values
        all_values = pd.concat([df_resampled['open'], df_resampled['high'], df_resampled['low'], df_resampled['close']])
        min_val = all_values.min()
        max_val = all_values.max()
        
        if data_type in ['nifty_call', 'nifty_put', 'banknifty_call', 'banknifty_put', 'midcpnifty_call', 'midcpnifty_put', 'sensex_call', 'sensex_put']:
            # For options data, use flexible range based on actual values
            if max_val > 1000 and min_val > 100:  # All values are large (like call data)
                min_price_threshold = 0.01
                max_price_threshold = max(10000, max_val * 1.5)
            elif max_val < 1000 and min_val > 0.1:  # All values are small (like put data)
                min_price_threshold = 0.01
                max_price_threshold = 1000
            else:
                # Mixed data or edge cases - use very permissive range
                min_price_threshold = 0.01
                max_price_threshold = max(10000, max_val * 2)  # Very permissive
        else:
            # For cash/future data, use higher thresholds
            min_price_threshold = 1000
            max_price_threshold = 1000000
        
        df_resampled_clean = df_resampled[(df_resampled['low'] >= min_price_threshold) & (df_resampled['close'] >= min_price_threshold) & 
                                         (df_resampled['low'] <= max_price_threshold) & (df_resampled['close'] <= max_price_threshold)]
        filtered_count = len(df_resampled_clean)
        print(f"  Original records: {original_count}, After filtering: {filtered_count}")
        
        if len(df_resampled_clean) == 0:
            return jsonify({'error': 'No valid data available for chart generation'})
        
        # Prepare chart data for interactive chart
        chart_data = []
        for _, row in df_resampled_clean.iterrows():
            chart_data.append({
                'time': row['time_readable'],
                'open': float(row['open']),
                'high': float(row['high']),
                'low': float(row['low']),
                'close': float(row['close'])
            })
        
        # Calculate time frame information
        time_frame_info = calculate_time_frame(df_resampled_clean)
        
        print(f"Returning response with timeframe: {interval_minutes}")
        
        return jsonify({
            'success': True,
            'chart_base64': chart_base64,
            'chart_title': chart_title,
            'record_count': len(df_resampled_clean),
            'chart_data': chart_data,
            'time_frame': time_frame_info,
            'data_source': data_type,
            'timeframe': interval_minutes
        })
        
    elif chart_type == 'summary':
        chart_base64 = create_summary_chart_base64(df, date, data_type, symbol)
        if chart_base64 is None:
            return jsonify({'error': 'Failed to generate summary chart'})
            
        # Use user-friendly names for chart titles
        display_names = {
            'nifty_cash': 'Spot',
            'nifty_future': 'Future',
            'nifty_call': 'Call',
            'nifty_put': 'Put',
            'banknifty_cash': 'Spot',
            'banknifty_future': 'Future',
            'banknifty_call': 'Call',
            'banknifty_put': 'Put',
            'midcpnifty_cash': 'Spot',
            'midcpnifty_future': 'Future',
            'midcpnifty_call': 'Call',
            'midcpnifty_put': 'Put',
            'sensex_cash': 'Spot',
            'sensex_future': 'Future',
            'sensex_call': 'Call',
            'sensex_put': 'Put'
        }
        data_type_display = display_names.get(data_type, data_type.replace('_', ' ').title())
        chart_title = f'Summary Chart - {date} ({data_type_display})'
        
        # Calculate time frame information for summary charts too
        time_frame_info = calculate_time_frame(df)
        
        return jsonify({
            'success': True,
            'chart_base64': chart_base64,
            'chart_title': chart_title,
            'record_count': len(df),
            'time_frame': time_frame_info,
            'data_source': data_type
        })
    else:
        return jsonify({'error': 'Invalid chart type'})

@app.route('/get_date_range')
def get_date_range_route():
    """API endpoint to get the date range for a specific data type and symbol"""
    data_type = request.args.get('data_type', 'nifty_cash')
    symbol = request.args.get('symbol', 'nifty')
    print(f"=== GET_DATE_RANGE_ROUTE DEBUG ===")
    print(f"  data_type: {data_type}")
    print(f"  symbol: {symbol}")
    
    date_range = get_date_range(data_type, symbol)
    print(f"  date_range result: {date_range}")
    
    if date_range is None:
        print(f"  WARNING: date_range is None, returning error response")
        return jsonify({'error': 'No date range found for the specified data type and symbol'})
    
    return jsonify({'date_range': date_range})

@app.route('/get_dates')
def get_dates():
    """API endpoint to get available dates for a specific data type"""
    data_type = request.args.get('data_type', 'nifty_cash')
    symbol = request.args.get('symbol', 'nifty')
    dates = get_available_dates(data_type, symbol)
    return jsonify({'dates': dates})

@app.route('/get_strikes')
def get_strikes():
    """API endpoint to get available strikes for a date and data type"""
    date = request.args.get('date')
    data_type = request.args.get('data_type')
    symbol = request.args.get('symbol', 'nifty')
    
    if not date or not data_type:
        return jsonify({'error': 'Date and data type are required'})
    
    strikes = get_available_strikes(date, data_type, symbol)
    return jsonify({'strikes': strikes})

@app.route('/get_expiries')
def get_expiries():
    """API endpoint to get available expiries for a date, data type, and strike"""
    date = request.args.get('date')
    data_type = request.args.get('data_type')
    strike = request.args.get('strike')
    symbol = request.args.get('symbol', 'nifty')
    
    if not date or not data_type or not strike:
        return jsonify({'error': 'Date, data type, and strike are required'})
    
    expiries = get_available_expiries(date, data_type, float(strike), symbol)
    return jsonify({'expiries': expiries})

@app.route('/test')
def test():
    """Test route to verify Flask is working"""
    return "Flask is working! This is a test route from All.py"

@app.route('/debug_tables')
def debug_tables():
    """Debug endpoint to check available tables and their data"""
    try:
        connection = get_db_connection()
        cursor = connection.cursor()
        
        # Get all tables
        cursor.execute("SHOW TABLES")
        all_tables = cursor.fetchall()
        table_names = [table[0] for table in all_tables]
        
        # Check each table for data
        table_info = {}
        for table_name in table_names:
            try:
                # Get row count
                cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                count = cursor.fetchone()[0]
                
                # Get date range if table has a date column
                try:
                    cursor.execute(f"SELECT MIN(date) as min_date, MAX(date) as max_date FROM {table_name}")
                    date_result = cursor.fetchone()
                    if date_result and date_result[0] and date_result[1]:
                        min_date = convert_db_date_to_readable(date_result[0])
                        max_date = convert_db_date_to_readable(date_result[1])
                        table_info[table_name] = {
                            'row_count': count,
                            'min_date': min_date,
                            'max_date': max_date,
                            'min_date_int': date_result[0],
                            'max_date_int': date_result[1]
                        }
                    else:
                        table_info[table_name] = {
                            'row_count': count,
                            'date_range': 'No date data'
                        }
                except:
                    table_info[table_name] = {
                        'row_count': count,
                        'date_range': 'No date column'
                    }
            except Exception as e:
                table_info[table_name] = {'error': str(e)}
        
        cursor.close()
        connection.close()
        
        return jsonify({
            'available_tables': table_names,
            'table_info': table_info
        })
        
    except Exception as e:
        return jsonify({'error': str(e)})

@app.route('/test_expiry_data')
def test_expiry_data():
    """Test endpoint to check what expiry data is available"""
    date = request.args.get('date', '2025-08-14')
    symbol = request.args.get('symbol', 'nifty')
    
    try:
        connection = get_db_connection()
        cursor = connection.cursor()
        db_date = convert_date_to_db_format(date)
        
        # Check what data is available for this date
        table_map = {
            'nifty': {
                'call_table': 'nifty_call',
                'put_table': 'nifty_put'
            }
        }
        
        symbol_tables = table_map.get(symbol, table_map['nifty'])
        call_table = symbol_tables['call_table']
        put_table = symbol_tables['put_table']
        
        # Get all expiries for the date
        cursor.execute(f"SELECT DISTINCT expiry FROM {call_table} WHERE date = %s ORDER BY expiry", (db_date,))
        call_expiries = [row[0] for row in cursor.fetchall()]
        
        cursor.execute(f"SELECT DISTINCT expiry FROM {put_table} WHERE date = %s ORDER BY expiry", (db_date,))
        put_expiries = [row[0] for row in cursor.fetchall()]
        
        # Get some sample strikes
        cursor.execute(f"SELECT DISTINCT strike FROM {call_table} WHERE date = %s ORDER BY strike LIMIT 10", (db_date,))
        sample_strikes = [row[0] for row in cursor.fetchall()]
        
        cursor.close()
        connection.close()
        
        return jsonify({
            'date': date,
            'db_date': db_date,
            'call_expiries': call_expiries,
            'put_expiries': put_expiries,
            'sample_strikes': sample_strikes
        })
        
    except Exception as e:
        return jsonify({'error': str(e)})

@app.route('/debug_dates')
def debug_dates():
    """Debug endpoint to check what dates are available"""
    data_type = request.args.get('data_type', 'nifty_call')
    symbol = request.args.get('symbol', 'nifty')
    
    try:
        print(f"=== DEBUG_DATES ===")
        print(f"data_type: {data_type}")
        print(f"symbol: {symbol}")
        
        dates = get_available_dates(data_type, symbol)
        print(f"Returned dates: {dates}")
        print(f"Number of dates: {len(dates)}")
        if dates:
            print(f"First date: {dates[0]}")
            print(f"Last date: {dates[-1]}")
        
        return jsonify({
            'data_type': data_type,
            'symbol': symbol,
            'dates': dates,
            'count': len(dates),
            'first_date': dates[0] if dates else None,
            'last_date': dates[-1] if dates else None
        })
        
    except Exception as e:
        print(f"Error in debug_dates: {e}")
        return jsonify({'error': str(e)})

@app.route('/debug_straddle_dates')
def debug_straddle_dates():
    """Debug endpoint specifically for straddle chart dates"""
    try:
        print(f"=== DEBUG_STRADDLE_DATES ===")
        
        # Test different data types for nifty
        call_dates = get_available_dates('nifty_call', 'nifty')
        put_dates = get_available_dates('nifty_put', 'nifty')
        cash_dates = get_available_dates('nifty_cash', 'nifty')
        
        print(f"Call dates count: {len(call_dates)}")
        print(f"Put dates count: {len(put_dates)}")
        print(f"Cash dates count: {len(cash_dates)}")
        
        if call_dates:
            print(f"Call first date: {call_dates[0]}")
            print(f"Call last date: {call_dates[-1]}")
        
        if put_dates:
            print(f"Put first date: {put_dates[0]}")
            print(f"Put last date: {put_dates[-1]}")
        
        if cash_dates:
            print(f"Cash first date: {cash_dates[0]}")
            print(f"Cash last date: {cash_dates[-1]}")
        
        return jsonify({
            'call_dates': {
                'count': len(call_dates),
                'first_date': call_dates[0] if call_dates else None,
                'last_date': call_dates[-1] if call_dates else None
            },
            'put_dates': {
                'count': len(put_dates),
                'first_date': put_dates[0] if put_dates else None,
                'last_date': put_dates[-1] if put_dates else None
            },
            'cash_dates': {
                'count': len(cash_dates),
                'first_date': cash_dates[0] if cash_dates else None,
                'last_date': cash_dates[-1] if cash_dates else None
            }
        })
        
    except Exception as e:
        print(f"Error in debug_straddle_dates: {e}")
        return jsonify({'error': str(e)})

@app.route('/straddle_chart')
def straddle_chart():
    """Straddle chart analysis page with symbol, date, strike, and expiry selection"""
    return render_template('straddle_index.html')

@app.route('/options_chain')
def options_chain():
    """Options chain analysis page showing all available strikes and expiries"""
    return render_template('options_chain_index.html')

@app.route('/get_straddle_strikes')
def get_straddle_strikes():
    """Get available call and put strikes for a specific date and symbol"""
    date = request.args.get('date')
    symbol = request.args.get('symbol', 'nifty')
    
    if not date:
        return jsonify({'error': 'Date is required'})
    
    try:
        # Determine table names based on symbol
        table_map = {
            'nifty': {
                'call_table': 'nifty_call',
                'put_table': 'nifty_put'
            },
            'banknifty': {
                'call_table': 'banknifty_call',
                'put_table': 'banknifty_put'
            },
            'midcpnifty': {
                'call_table': 'midcpnifty_call',
                'put_table': 'midcpnifty_put'
            },
            'sensex': {
                'call_table': 'sensex_call',
                'put_table': 'sensex_put'
            }
        }
        
        symbol_tables = table_map.get(symbol, table_map['nifty'])
        call_table = symbol_tables['call_table']
        put_table = symbol_tables['put_table']
        
        connection = get_db_connection()
        cursor = connection.cursor()
        db_date = convert_date_to_db_format(date)
        
        # Get call strikes
        cursor.execute(f"SELECT DISTINCT strike FROM {call_table} WHERE date = %s ORDER BY strike", (db_date,))
        call_strikes = [float(row[0]) for row in cursor.fetchall()]
        
        # Get put strikes
        cursor.execute(f"SELECT DISTINCT strike FROM {put_table} WHERE date = %s ORDER BY strike", (db_date,))
        put_strikes = [float(row[0]) for row in cursor.fetchall()]
        
        cursor.close()
        connection.close()
        
        return jsonify({
            'call_strikes': call_strikes,
            'put_strikes': put_strikes
        })
        
    except Exception as e:
        print(f"Error getting straddle strikes: {e}")
        return jsonify({'error': str(e)})

@app.route('/get_straddle_expiries')
def get_straddle_expiries():
    """Get available expiry dates for call and put strikes on a specific date"""
    date = request.args.get('date')
    call_strike = request.args.get('call_strike')
    put_strike = request.args.get('put_strike')
    symbol = request.args.get('symbol', 'nifty')
    
    print(f"=== GET_STRADDLE_EXPIRIES DEBUG ===")
    print(f"Received parameters:")
    print(f"  date: {date}")
    print(f"  call_strike: {call_strike}")
    print(f"  put_strike: {put_strike}")
    print(f"  symbol: {symbol}")
    
    if not date or not call_strike or not put_strike:
        print("Missing required parameters")
        return jsonify({'error': 'Date, call strike, and put strike are required'})
    
    try:
        # Convert strikes to float
        call_strike = float(call_strike)
        put_strike = float(put_strike)
        
        # Determine table names based on symbol
        table_map = {
            'nifty': {
                'call_table': 'nifty_call',
                'put_table': 'nifty_put'
            },
            'banknifty': {
                'call_table': 'banknifty_call',
                'put_table': 'banknifty_put'
            },
            'midcpnifty': {
                'call_table': 'midcpnifty_call',
                'put_table': 'midcpnifty_put'
            },
            'sensex': {
                'call_table': 'sensex_call',
                'put_table': 'sensex_put'
            }
        }
        
        symbol_tables = table_map.get(symbol, table_map['nifty'])
        call_table = symbol_tables['call_table']
        put_table = symbol_tables['put_table']
        
        print(f"Using tables: {call_table}, {put_table}")
        
        connection = get_db_connection()
        cursor = connection.cursor()
        db_date = convert_date_to_db_format(date)
        
        print(f"Database date format: {db_date}")
        
        # Get call expiries for the selected strike
        call_query = f"SELECT DISTINCT expiry FROM {call_table} WHERE date = %s AND strike = %s ORDER BY expiry"
        print(f"Call query: {call_query} with params: {db_date}, {call_strike}")
        cursor.execute(call_query, (db_date, call_strike))
        call_expiries = [row[0] for row in cursor.fetchall()]
        print(f"Call expiries found: {call_expiries}")
        
        # Get put expiries for the selected strike
        put_query = f"SELECT DISTINCT expiry FROM {put_table} WHERE date = %s AND strike = %s ORDER BY expiry"
        print(f"Put query: {put_query} with params: {db_date}, {put_strike}")
        cursor.execute(put_query, (db_date, put_strike))
        put_expiries = [row[0] for row in cursor.fetchall()]
        print(f"Put expiries found: {put_expiries}")
        
        cursor.close()
        connection.close()
        
        # Find common expiries (both call and put should have the same expiry for straddle)
        common_expiries = list(set(call_expiries) & set(put_expiries))
        common_expiries.sort()
        
        print(f"Common expiries: {common_expiries}")
        
        # If no common expiries, try a more flexible approach
        if not common_expiries:
            print("No common expiries found, trying alternative approach...")
            # Get all expiries for the date regardless of strike
            connection = mysql.connector.connect(**DB_CONFIG)
            cursor = connection.cursor()
            
            # Get all expiries for the date
            all_expiries_query = f"SELECT DISTINCT expiry FROM {call_table} WHERE date = %s ORDER BY expiry"
            cursor.execute(all_expiries_query, (db_date,))
            all_expiries = [row[0] for row in cursor.fetchall()]
            print(f"All expiries for date: {all_expiries}")
            
            cursor.close()
            connection.close()
            
            # Use all available expiries as fallback
            common_expiries = all_expiries
        
        return jsonify({
            'call_expiries': call_expiries,
            'put_expiries': put_expiries,
            'common_expiries': common_expiries
        })
        
    except Exception as e:
        print(f"Error getting straddle expiries: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)})

@app.route('/get_straddle_dates')
def get_straddle_dates():
    """API endpoint to get available dates for straddle strategy (intersection of call and put)"""
    symbol = request.args.get('symbol', 'nifty')
    
    try:
        connection = get_db_connection()
        cursor = connection.cursor()
        
        # Use our optimized get_available_dates function instead of direct queries
        call_data_type = f'{symbol}_call'
        put_data_type = f'{symbol}_put'
        
        print(f"Getting call dates using optimized function...")
        call_dates_readable = get_available_dates(call_data_type, symbol)
        print(f"Getting put dates using optimized function...")
        put_dates_readable = get_available_dates(put_data_type, symbol)
        
        # Convert readable dates back to sets for intersection
        call_dates_set = set(call_dates_readable)
        put_dates_set = set(put_dates_readable)
        
        # Find intersection dates (where both call and put data exist)
        intersection_dates_set = call_dates_set.intersection(put_dates_set)
        readable_dates = sorted(list(intersection_dates_set))
        
        print(f"Call dates: {len(call_dates_readable)}, Put dates: {len(put_dates_readable)}, Intersection: {len(readable_dates)}")
        
        cursor.close()
        connection.close()
        
        print(f"=== STRADDLE_DATES_DEBUG ===")
        print(f"Symbol: {symbol}")
        print(f"Call dates count: {len(call_dates_readable)}")
        print(f"Put dates count: {len(put_dates_readable)}")
        print(f"Intersection dates count: {len(readable_dates)}")
        
        return jsonify({
            'dates': readable_dates,
            'call_dates_count': len(call_dates_readable),
            'put_dates_count': len(put_dates_readable),
            'intersection_dates_count': len(readable_dates)
        })
        
    except Exception as e:
        print(f"Error in get_straddle_dates: {e}")
        return jsonify({'error': str(e)})

@app.route('/generate_straddle_chart', methods=['POST'])
def generate_straddle_chart():
    """Generate straddle chart based on selected parameters"""
    date = request.form.get('date')
    symbol = request.form.get('symbol', 'nifty')
    call_strike = request.form.get('callStrike')  # Fixed: match HTML form field name
    put_strike = request.form.get('putStrike')    # Fixed: match HTML form field name
    expiry = request.form.get('expiry')
    timeframe = request.form.get('timeframe', '1')  # Get timeframe parameter
    
    print(f"=== STRADDLE CHART GENERATION DEBUG ===")
    print(f"Received parameters:")
    print(f"  date: {date}")
    print(f"  symbol: {symbol}")
    print(f"  call_strike: {call_strike} (type: {type(call_strike)})")
    print(f"  put_strike: {put_strike} (type: {type(put_strike)})")
    print(f"  expiry: {expiry} (type: {type(expiry)})")
    print(f"  timeframe: '{timeframe}' (type: {type(timeframe)})")
    
    # Convert strikes to float if they're strings
    try:
        call_strike = float(call_strike) if call_strike else None
        put_strike = float(put_strike) if put_strike else None
        print(f"Converted strikes - call: {call_strike}, put: {put_strike}")
    except ValueError as e:
        print(f"Error converting strikes to float: {e}")
        return jsonify({'error': 'Invalid strike price format'})
    
    # Convert timeframe to integer
    try:
        interval_minutes = int(timeframe)
        print(f"Converted timeframe '{timeframe}' to interval_minutes: {interval_minutes}")
    except ValueError:
        interval_minutes = 1
        print(f"Failed to convert timeframe '{timeframe}', using default: {interval_minutes}")
    
    # Validate timeframe
    if interval_minutes < 1 or interval_minutes > 60:
        interval_minutes = 1
        print(f"Timeframe {interval_minutes} out of range, using default: 1")
    
    if not all([date, call_strike, put_strike, expiry]):
        return jsonify({'error': 'All parameters are required'})
    
    try:
        # Determine table names based on symbol
        table_map = {
            'nifty': {
                'call_table': 'nifty_call',
                'put_table': 'nifty_put'
            },
            'banknifty': {
                'call_table': 'banknifty_call',
                'put_table': 'banknifty_put'
            },
            'midcpnifty': {
                'call_table': 'midcpnifty_call',
                'put_table': 'midcpnifty_put'
            },
            'sensex': {
                'call_table': 'sensex_call',
                'put_table': 'sensex_put'
            }
        }
        
        symbol_tables = table_map.get(symbol, table_map['nifty'])
        call_table = symbol_tables['call_table']
        put_table = symbol_tables['put_table']
        
        # Get call data
        print(f"Getting call data for table: {call_table}, strike: {call_strike}, expiry: {expiry}")
        call_df = get_ohlc_data_for_date(date, call_table, call_strike, expiry, symbol)
        if call_df is None:
            print(f"No call data found for strike {call_strike} and expiry {expiry}")
            return jsonify({
                'error': f'No call data found for strike {call_strike} and expiry {expiry} on {date}. '
                        f'Please try a different strike price or expiry date that has available data.'
            })
        print(f"Call data retrieved: {len(call_df)} records")
        
        # Get put data
        print(f"Getting put data for table: {put_table}, strike: {put_strike}, expiry: {expiry}")
        put_df = get_ohlc_data_for_date(date, put_table, put_strike, expiry, symbol)
        if put_df is None:
            print(f"No put data found for strike {put_strike} and expiry {expiry}")
            return jsonify({
                'error': f'No put data found for strike {put_strike} and expiry {expiry} on {date}. '
                        f'Please try a different strike price or expiry date that has available data.'
            })
        print(f"Put data retrieved: {len(put_df)} records")
        
        # Create straddle data by combining call and put prices
        print("Creating straddle data...")
        straddle_df = create_straddle_data(call_df, put_df, call_strike, put_strike)
        if straddle_df is None:
            print("Failed to create straddle data")
            return jsonify({
                'error': f'Unable to combine call and put data for the selected parameters. '
                        f'This usually happens when the strike prices have very different trading times. '
                        f'Try selecting strike prices that are closer together or use the same strike for both call and put.'
            })
        print(f"Straddle data created: {len(straddle_df)} records")
        
        # Check if we have sufficient data for chart generation
        if len(straddle_df) < 2:
            print(f"Insufficient data for chart generation: only {len(straddle_df)} record(s) available")
            return jsonify({
                'error': f'Insufficient data for chart generation. Only {len(straddle_df)} data point(s) available. '
                        f'For meaningful straddle analysis, at least 2 data points are required. '
                        f'Try selecting different strike prices or a different date with more trading activity.'
            })
        
        # Resample data to selected timeframe if not 1 minute
        if interval_minutes > 1:
            straddle_df_resampled = resample_straddle_data(straddle_df, interval_minutes)
            if straddle_df_resampled is None:
                print("Failed to resample straddle data, using original data")
                straddle_df_resampled = straddle_df
            else:
                print(f"Resampled data: {len(straddle_df_resampled)} records")
                straddle_df = straddle_df_resampled
        else:
            print("Using 1-minute data (no resampling needed)")
        
        # Get indicators from request
        indicators = request.form.getlist('indicators') if request.form.get('indicators') else []
        
        # Generate straddle chart
        chart_base64 = create_straddle_chart_base64(straddle_df, date, symbol, call_strike, put_strike, expiry, indicators)
        if chart_base64 is None:
            return jsonify({
                'error': f'Unable to generate chart with the available data. '
                        f'This might be due to insufficient data points or chart generation issues. '
                        f'Please try different parameters or contact support if the issue persists.'
            })
        
        # Prepare chart data for interactive chart
        chart_data = []
        for _, row in straddle_df.iterrows():
            chart_data.append({
                'time': row['time_readable'],
                'open': float(row['straddle_open']),
                'high': float(row['straddle_high']),
                'low': float(row['straddle_low']),
                'close': float(row['straddle_close']),
                'call_price': float(row['call_close']),
                'put_price': float(row['put_close'])
            })
        
        # Calculate time frame information
        time_frame_info = calculate_time_frame(straddle_df)
        
        # Update chart title to include timeframe
        if interval_minutes == 1:
            chart_title = f'Straddle Chart - {symbol.upper()} Call {call_strike} + Put {put_strike} ({date}) - Expiry: {expiry}'
        else:
            chart_title = f'{interval_minutes}-Minute Straddle Chart - {symbol.upper()} Call {call_strike} + Put {put_strike} ({date}) - Expiry: {expiry}'
        
        return jsonify({
            'success': True,
            'chart_base64': chart_base64,
            'chart_title': chart_title,
            'record_count': len(straddle_df),
            'chart_data': chart_data,
            'time_frame': time_frame_info,
            'call_strike': call_strike,
            'put_strike': put_strike,
            'expiry': expiry,
            'timeframe': interval_minutes
        })
        
    except Exception as e:
        print(f"Error generating straddle chart: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'error': f'An unexpected error occurred while generating the straddle chart: {str(e)}. '
                    f'Please try again with different parameters or contact support if the issue persists.'
        })

def create_straddle_data(call_df, put_df, call_strike, put_strike):
    """Create straddle data by combining call and put prices"""
    try:
        print(f"=== CREATE_STRADDLE_DATA DEBUG ===")
        print(f"Call DF shape: {call_df.shape if call_df is not None else 'None'}")
        print(f"Put DF shape: {put_df.shape if put_df is not None else 'None'}")
        
        if call_df is None or put_df is None:
            print("One or both dataframes are None")
            return None
            
        # Ensure both dataframes have the same time structure
        call_df = call_df.copy()
        put_df = put_df.copy()
        
        print(f"Call DF columns: {list(call_df.columns)}")
        print(f"Put DF columns: {list(put_df.columns)}")
        
        # Create time key for merging
        call_df['time_key'] = call_df['time']
        put_df['time_key'] = put_df['time']
        
        print(f"Call DF time range: {call_df['time'].min()} to {call_df['time'].max()}")
        print(f"Put DF time range: {put_df['time'].min()} to {put_df['time'].max()}")
        print(f"Call DF unique times: {len(call_df['time'].unique())}")
        print(f"Put DF unique times: {len(put_df['time'].unique())}")
        
        # Check for overlapping time ranges
        call_times = set(call_df['time'].unique())
        put_times = set(put_df['time'].unique())
        common_times = call_times.intersection(put_times)
        print(f"Common time points: {len(common_times)}")
        
        # For different strike prices, we need a more flexible merging approach
        # First try inner join (exact time match)
        merged_df = pd.merge(call_df, put_df, on='time_key', how='inner', suffixes=('_call', '_put'))
        
        print(f"Inner join result shape: {merged_df.shape}")
        
        # If inner join fails (different strike prices often have different time data),
        # try outer join and forward fill missing values
        if len(merged_df) == 0:
            print("Inner join failed, trying outer join with forward fill...")
            merged_df = pd.merge(call_df, put_df, on='time_key', how='outer', suffixes=('_call', '_put'))
            print(f"Outer join result shape: {merged_df.shape}")
            
            # Sort by time to ensure proper forward filling
            merged_df = merged_df.sort_values('time_key')
            
            # Forward fill missing values for OHLC data
            ohlc_columns = ['open_call', 'high_call', 'low_call', 'close_call', 
                           'open_put', 'high_put', 'low_put', 'close_put']
            
            for col in ohlc_columns:
                if col in merged_df.columns:
                    merged_df[col] = merged_df[col].ffill()
            
            # Remove rows where we still don't have both call and put data
            merged_df = merged_df.dropna(subset=['open_call', 'open_put'])
            print(f"After forward fill and cleanup: {merged_df.shape}")
        
        if len(merged_df) == 0:
            print("No matching time records between call and put data after all attempts")
            print("Trying time-based interpolation approach...")
            
            # Alternative approach: Create a unified time series and interpolate
            # Get all unique time points from both datasets
            all_times = sorted(set(call_df['time_key'].tolist() + put_df['time_key'].tolist()))
            print(f"Total unique time points: {len(all_times)}")
            
            # Create a base dataframe with all time points
            base_df = pd.DataFrame({'time_key': all_times})
            
            # Merge call data
            call_merged = pd.merge(base_df, call_df, on='time_key', how='left')
            # Forward fill call data
            call_ohlc_cols = ['open', 'high', 'low', 'close']
            for col in call_ohlc_cols:
                if col in call_merged.columns:
                    call_merged[col] = call_merged[col].ffill()
            
            # Merge put data
            put_merged = pd.merge(base_df, put_df, on='time_key', how='left')
            # Forward fill put data
            for col in call_ohlc_cols:
                if col in put_merged.columns:
                    put_merged[col] = put_merged[col].ffill()
            
            # Combine call and put data
            merged_df = pd.merge(call_merged, put_merged, on='time_key', suffixes=('_call', '_put'))
            
            # Remove rows where we still don't have both call and put data
            merged_df = merged_df.dropna(subset=['open_call', 'open_put'])
            print(f"After interpolation approach: {merged_df.shape}")
            
            if len(merged_df) == 0:
                print("All merging approaches failed")
                print("Trying final fallback: use available data with minimal overlap...")
                
                # Final fallback: Use the dataset with more data points and fill missing values
                if len(call_df) >= len(put_df):
                    print("Using call data as base and filling put data")
                    base_df = call_df.copy()
                    base_df['time_key'] = base_df['time']
                    
                    # Merge put data with forward fill
                    put_merged = pd.merge(base_df[['time_key']], put_df, on='time_key', how='left')
                    for col in ['open', 'high', 'low', 'close']:
                        if col in put_merged.columns:
                            put_merged[col] = put_merged[col].ffill().bfill()
                    
                    merged_df = pd.merge(base_df, put_merged, on='time_key', suffixes=('_call', '_put'))
                else:
                    print("Using put data as base and filling call data")
                    base_df = put_df.copy()
                    base_df['time_key'] = base_df['time']
                    
                    # Merge call data with forward fill
                    call_merged = pd.merge(base_df[['time_key']], call_df, on='time_key', how='left')
                    for col in ['open', 'high', 'low', 'close']:
                        if col in call_merged.columns:
                            call_merged[col] = call_merged[col].ffill().bfill()
                    
                    merged_df = pd.merge(base_df, call_merged, on='time_key', suffixes=('_put', '_call'))
                
                # Remove rows where we still don't have both call and put data
                merged_df = merged_df.dropna(subset=['open_call', 'open_put'])
                print(f"After final fallback: {merged_df.shape}")
                
                if len(merged_df) == 0:
                    print("All approaches failed - cannot create straddle data")
                    return None
        
        # Scale down prices (convert from paise to rupees)
        merged_df['call_open'] = merged_df['open_call'] / 100
        merged_df['call_high'] = merged_df['high_call'] / 100
        merged_df['call_low'] = merged_df['low_call'] / 100
        merged_df['call_close'] = merged_df['close_call'] / 100
        
        merged_df['put_open'] = merged_df['open_put'] / 100
        merged_df['put_high'] = merged_df['high_put'] / 100
        merged_df['put_low'] = merged_df['low_put'] / 100
        merged_df['put_close'] = merged_df['close_put'] / 100
        
        # Calculate straddle prices (call + put)
        merged_df['straddle_open'] = merged_df['call_open'] + merged_df['put_open']
        merged_df['straddle_high'] = merged_df['call_high'] + merged_df['put_high']
        merged_df['straddle_low'] = merged_df['call_low'] + merged_df['put_low']
        merged_df['straddle_close'] = merged_df['call_close'] + merged_df['put_close']
        
        # Debug: Check what columns are actually available
        print(f"Available columns in merged_df: {list(merged_df.columns)}")
        
        # Keep only necessary columns - use the actual column names that exist
        try:
            result_df = merged_df[[
                'time_key', 'date_readable_call', 'time_readable_call',
                'straddle_open', 'straddle_high', 'straddle_low', 'straddle_close',
                'call_open', 'call_high', 'call_low', 'call_close',
                'put_open', 'put_high', 'put_low', 'put_close'
            ]].copy()
            print(f"Successfully selected columns, result shape: {result_df.shape}")
        except KeyError as e:
            print(f"ERROR: Missing columns: {e}")
            print("Available columns:", list(merged_df.columns))
            # Use only the columns that exist
            available_cols = ['time_key']
            for col in ['date_readable_call', 'time_readable_call', 'straddle_open', 'straddle_high', 'straddle_low', 'straddle_close', 'call_open', 'call_high', 'call_low', 'call_close', 'put_open', 'put_high', 'put_low', 'put_close']:
                if col in merged_df.columns:
                    available_cols.append(col)
                else:
                    print(f"Column '{col}' not found")
            
            result_df = merged_df[available_cols].copy()
            print(f"Using available columns: {list(result_df.columns)}")
        
        # Rename columns for consistency
        result_df.rename(columns={
            'time_key': 'time',
            'date_readable_call': 'date_readable',
            'time_readable_call': 'time_readable'
        }, inplace=True)
        
        return result_df
        
    except Exception as e:
        print(f"Error creating straddle data: {e}")
        import traceback
        traceback.print_exc()
        return None

def create_straddle_chart_base64(df, date, symbol, call_strike, put_strike, expiry, indicators=None):
    """Create a single interactive straddle candlestick chart with indicators and return as base64 string"""
    print(f"=== STRADDLE CHART CREATION DEBUG ===")
    print(f"DataFrame is None: {df is None}")
    print(f"DataFrame length: {len(df) if df is not None else 'N/A'}")
    print(f"Indicators received: {indicators}")
    
    if df is None or len(df) == 0:
        print("ERROR: DataFrame is None or empty")
        return None
    
    try:
        # Create datetime index for proper time series plotting
        df['datetime'] = pd.to_datetime(df['date_readable'] + ' ' + df['time_readable'])
        df.set_index('datetime', inplace=True)
        
        # Set dark theme style
        plt.style.use('dark_background')
        
        # Set up the plot with dark theme - single chart only
        fig, ax = plt.subplots(1, 1, figsize=(16, 9), facecolor='#1a1a1a')
        fig.patch.set_facecolor('#1a1a1a')
        ax.set_facecolor('#1a1a1a')
        
        # Enhanced color scheme for straddle chart
        straddle_colors = {
            'bull': '#00ff88',      # Bright green for bullish straddle
            'bear': '#ff4444',      # Bright red for bearish straddle
            'edge_bull': '#00cc66', # Darker green for edges
            'edge_bear': '#cc3333', # Darker red for edges
            'shadow': '#222222',    # Shadow color for depth
        }
        
        # Plot straddle candlesticks
        for i, (idx, row) in enumerate(df.iterrows()):
            open_price = row['straddle_open']
            close_price = row['straddle_close']
            high_price = row['straddle_high']
            low_price = row['straddle_low']
            
            if close_price >= open_price:
                color = straddle_colors['bull']
                edge_color = straddle_colors['edge_bull']
                wick_color = straddle_colors['bull']
            else:
                color = straddle_colors['bear']
                edge_color = straddle_colors['edge_bear']
                wick_color = straddle_colors['bear']
            
            # Plot the wick (vertical line from low to high)
            ax.plot([i, i], [low_price, high_price], color=wick_color, linewidth=1.5, alpha=0.9)
            
            # Plot the body
            body_height = abs(close_price - open_price)
            body_bottom = min(open_price, close_price)
            
            if body_height > 0:
                # Create proper candlestick body with better proportions
                rect = patches.Rectangle((i - 0.25, body_bottom), 0.5, body_height, 
                                       facecolor=color, edgecolor=edge_color, linewidth=1.0, alpha=0.9)
                ax.add_patch(rect)
                
                # Add subtle shadow effect for depth
                shadow_rect = patches.Rectangle((i - 0.22, body_bottom - 0.02), 0.44, body_height + 0.04, 
                                              facecolor=straddle_colors['shadow'], edgecolor='none', alpha=0.3)
                ax.add_patch(shadow_rect)
            else:
                # Doji (when open = close) - horizontal line
                ax.plot([i - 0.25, i + 0.25], [open_price, open_price], color=edge_color, linewidth=2)
        
        # Plot indicators if specified
        print(f"=== STRADDLE CHART INDICATORS DEBUG ===")
        print(f"Indicators received: {indicators}")
        print(f"Indicators type: {type(indicators)}")
        
        if indicators:
            print(f"Processing {len(indicators)} indicators in straddle chart")
            for indicator in indicators:
                print(f"Processing indicator: {indicator}")
                if indicator == 'vwap':
                    print("VWAP indicator detected in straddle chart, calculating...")
                    vwap_values = calculate_vwap(df)
                    print(f"VWAP values returned: {vwap_values is not None}")
                    if vwap_values is not None:
                        print(f"Plotting VWAP line with {len(vwap_values)} points")
                        ax.plot(range(len(vwap_values)), vwap_values, color='#ff6b6b', linewidth=2, 
                               label='VWAP', alpha=0.8)
                        print("VWAP line plotted successfully in straddle chart")
                    else:
                        print("VWAP values are None, not plotting in straddle chart")
                
                elif indicator == 'sma_20':
                    print("SMA indicator detected, but it's not implemented yet")
                
                elif indicator == 'ema_20':
                    print("*** EMA 20 INDICATOR DETECTED ***")
                    print(f"DataFrame columns available: {list(df.columns)}")
                    print(f"DataFrame length: {len(df)}")
                    print(f"DataFrame shape: {df.shape}")
                    if 'straddle_close' in df.columns:
                        print("straddle_close column found, proceeding with EMA calculation")
                        print(f"First few straddle_close values: {df['straddle_close'].head()}")
                        ema_20_values = calculate_ema(df, period=20, price_column='straddle_close')
                        print(f"EMA 20 values returned: {ema_20_values is not None}")
                        if ema_20_values is not None:
                            print(f"*** PLOTTING EMA 20 LINE ***")
                            print(f"Number of EMA points: {len(ema_20_values)}")
                            print(f"EMA 20 values range: {min(ema_20_values):.2f} to {max(ema_20_values):.2f}")
                            print(f"First 5 EMA values: {ema_20_values[:5]}")
                            print(f"Last 5 EMA values: {ema_20_values[-5:]}")
                            
                            # Plot EMA line with very visible styling - plot AFTER candlesticks
                            ax.plot(range(len(ema_20_values)), ema_20_values, 
                                   color='#ff0000', linewidth=6, label='EMA (Close, 20)', 
                                   alpha=1.0, linestyle='-', zorder=100, marker='o', markersize=2)
                            print("*** EMA 20 LINE PLOTTED SUCCESSFULLY ***")
                            
                            # Ensure the line is visible by adjusting plot limits
                            all_values = list(ema_20_values) + list(df['straddle_close'])
                            y_min = min(all_values) * 0.995
                            y_max = max(all_values) * 1.005
                            ax.set_ylim(y_min, y_max)
                            print(f"Chart limits after EMA: x={ax.get_xlim()}, y={ax.get_ylim()}")
                            print(f"EMA line should be visible between {min(ema_20_values):.2f} and {max(ema_20_values):.2f}")
                        else:
                            print("*** ERROR: EMA 20 values are None ***")
                    else:
                        print("*** ERROR: straddle_close column not found in DataFrame ***")
                        print(f"Available columns: {list(df.columns)}")
                
                elif indicator == 'ema_50':
                    print("*** EMA 50 INDICATOR DETECTED ***")
                    print(f"DataFrame columns available: {list(df.columns)}")
                    print(f"DataFrame length: {len(df)}")
                    print(f"DataFrame shape: {df.shape}")
                    if 'straddle_close' in df.columns:
                        print("straddle_close column found, proceeding with EMA calculation")
                        print(f"First few straddle_close values: {df['straddle_close'].head()}")
                        ema_50_values = calculate_ema(df, period=50, price_column='straddle_close')
                        print(f"EMA 50 values returned: {ema_50_values is not None}")
                        if ema_50_values is not None:
                            print(f"*** PLOTTING EMA 50 LINE ***")
                            print(f"Number of EMA points: {len(ema_50_values)}")
                            print(f"EMA 50 values range: {min(ema_50_values):.2f} to {max(ema_50_values):.2f}")
                            print(f"First 5 EMA values: {ema_50_values[:5]}")
                            print(f"Last 5 EMA values: {ema_50_values[-5:]}")
                            
                            # Plot EMA line with very visible styling - plot AFTER candlesticks
                            ax.plot(range(len(ema_50_values)), ema_50_values, 
                                   color='#00ff00', linewidth=6, label='EMA (Close, 50)', 
                                   alpha=1.0, linestyle='-', zorder=100, marker='o', markersize=2)
                            print("*** EMA 50 LINE PLOTTED SUCCESSFULLY ***")
                            
                            # Ensure the line is visible by adjusting plot limits
                            all_values = list(ema_50_values) + list(df['straddle_close'])
                            y_min = min(all_values) * 0.995
                            y_max = max(all_values) * 1.005
                            ax.set_ylim(y_min, y_max)
                            print(f"Chart limits after EMA: x={ax.get_xlim()}, y={ax.get_ylim()}")
                            print(f"EMA line should be visible between {min(ema_50_values):.2f} and {max(ema_50_values):.2f}")
                        else:
                            print("*** ERROR: EMA 50 values are None ***")
                    else:
                        print("*** ERROR: straddle_close column not found in DataFrame ***")
                        print(f"Available columns: {list(df.columns)}")
                
                elif indicator == 'ema_100':
                    print("*** EMA 100 INDICATOR DETECTED ***")
                    print(f"DataFrame columns available: {list(df.columns)}")
                    print(f"DataFrame length: {len(df)}")
                    print(f"DataFrame shape: {df.shape}")
                    if 'straddle_close' in df.columns:
                        print("straddle_close column found, proceeding with EMA calculation")
                        print(f"First few straddle_close values: {df['straddle_close'].head()}")
                        ema_100_values = calculate_ema(df, period=100, price_column='straddle_close')
                        print(f"EMA 100 values returned: {ema_100_values is not None}")
                        if ema_100_values is not None:
                            print(f"*** PLOTTING EMA 100 LINE ***")
                            print(f"Number of EMA points: {len(ema_100_values)}")
                            print(f"EMA 100 values range: {min(ema_100_values):.2f} to {max(ema_100_values):.2f}")
                            print(f"First 5 EMA values: {ema_100_values[:5]}")
                            print(f"Last 5 EMA values: {ema_100_values[-5:]}")
                            
                            # Plot EMA line with very visible styling - plot AFTER candlesticks
                            ax.plot(range(len(ema_100_values)), ema_100_values, 
                                   color='#9b59b6', linewidth=6, label='EMA (Close, 100)', 
                                   alpha=1.0, linestyle='-', zorder=100, marker='o', markersize=2)
                            print("*** EMA 100 LINE PLOTTED SUCCESSFULLY ***")
                            
                            # Ensure the line is visible by adjusting plot limits
                            all_values = list(ema_100_values) + list(df['straddle_close'])
                            y_min = min(all_values) * 0.995
                            y_max = max(all_values) * 1.005
                            ax.set_ylim(y_min, y_max)
                            print(f"Chart limits after EMA: x={ax.get_xlim()}, y={ax.get_ylim()}")
                            print(f"EMA line should be visible between {min(ema_100_values):.2f} and {max(ema_100_values):.2f}")
                        else:
                            print("*** ERROR: EMA 100 values are None ***")
                    else:
                        print("*** ERROR: straddle_close column not found in DataFrame ***")
                        print(f"Available columns: {list(df.columns)}")
                
                elif indicator == 'ema_200':
                    print("*** EMA 200 INDICATOR DETECTED ***")
                    print(f"DataFrame columns available: {list(df.columns)}")
                    print(f"DataFrame length: {len(df)}")
                    print(f"DataFrame shape: {df.shape}")
                    if 'straddle_close' in df.columns:
                        print("straddle_close column found, proceeding with EMA calculation")
                        print(f"First few straddle_close values: {df['straddle_close'].head()}")
                        ema_200_values = calculate_ema(df, period=200, price_column='straddle_close')
                        print(f"EMA 200 values returned: {ema_200_values is not None}")
                        if ema_200_values is not None:
                            print(f"*** PLOTTING EMA 200 LINE ***")
                            print(f"Number of EMA points: {len(ema_200_values)}")
                            print(f"EMA 200 values range: {min(ema_200_values):.2f} to {max(ema_200_values):.2f}")
                            print(f"First 5 EMA values: {ema_200_values[:5]}")
                            print(f"Last 5 EMA values: {ema_200_values[-5:]}")
                            
                            # Plot EMA line with very visible styling - plot AFTER candlesticks
                            ax.plot(range(len(ema_200_values)), ema_200_values, 
                                   color='#e74c3c', linewidth=6, label='EMA (Close, 200)', 
                                   alpha=1.0, linestyle='-', zorder=100, marker='o', markersize=2)
                            print("*** EMA 200 LINE PLOTTED SUCCESSFULLY ***")
                            
                            # Ensure the line is visible by adjusting plot limits
                            all_values = list(ema_200_values) + list(df['straddle_close'])
                            y_min = min(all_values) * 0.995
                            y_max = max(all_values) * 1.005
                            ax.set_ylim(y_min, y_max)
                            print(f"Chart limits after EMA: x={ax.get_xlim()}, y={ax.get_ylim()}")
                            print(f"EMA line should be visible between {min(ema_200_values):.2f} and {max(ema_200_values):.2f}")
                        else:
                            print("*** ERROR: EMA 200 values are None ***")
                    else:
                        print("*** ERROR: straddle_close column not found in DataFrame ***")
                        print(f"Available columns: {list(df.columns)}")
        else:
            print("*** NO INDICATORS RECEIVED IN STRADDLE CHART ***")
        
        # Customize the straddle chart
        symbol_display = symbol.upper()
        # Note: timeframe will be added by the calling function
        title = f'{symbol_display} Straddle Chart - Call {call_strike} + Put {put_strike} ({date}) - Expiry: {expiry}'
        
        ax.set_title(title, fontsize=18, fontweight='bold', color='#ffffff', pad=20)
        ax.set_xlabel('Time', fontsize=14, color='#cccccc', fontweight='bold')
        ax.set_ylabel('Straddle Price (INR)', fontsize=14, color='#cccccc', fontweight='bold')
        # Enhanced grid styling
        ax.grid(True, alpha=0.15, color='#333333', linewidth=0.5, linestyle='-')
        ax.set_axisbelow(True)
        
        # Set x-axis limits with proper spacing
        ax.set_xlim(-0.5, len(df) - 0.5)
        
        # Adjust spacing for better candlestick visibility
        if len(df) > 50:
            # For many data points, reduce spacing
            ax.set_xlim(-0.3, len(df) - 0.7)
        elif len(df) > 20:
            # For moderate data points, standard spacing
            ax.set_xlim(-0.4, len(df) - 0.6)
        
        # Set x-axis labels for straddle chart
        n_points = len(df)
        if n_points > 30:
            step = max(1, n_points // 12)
            x_ticks = range(0, n_points, step)
            x_labels = [df.index[i].strftime('%H:%M') for i in x_ticks]
        elif n_points > 15:
            step = max(1, n_points // 10)
            x_ticks = range(0, n_points, step)
            x_labels = [df.index[i].strftime('%H:%M') for i in x_ticks]
        else:
            x_ticks = range(n_points)
            x_labels = [df.index[i].strftime('%H:%M') for i in x_ticks]
        
        ax.set_xticks(x_ticks)
        ax.set_xticklabels(x_labels, rotation=45, color='#cccccc', fontsize=10)
        # Enhanced y-axis formatting
        ax.tick_params(axis='y', colors='#cccccc', labelsize=11)
        
        # Format y-axis labels with proper currency formatting
        def format_price(x, pos):
            return f'₹{x:,.0f}'
        
        ax.yaxis.set_major_formatter(plt.FuncFormatter(format_price))
        
        # Add straddle statistics box
        current_straddle = df['straddle_close'].iloc[-1]
        straddle_change = current_straddle - df['straddle_open'].iloc[0]
        straddle_change_pct = (straddle_change / df['straddle_open'].iloc[0]) * 100
        
        stats_text = f"""Straddle O {df['straddle_open'].iloc[0]:,.2f}
Straddle H {df['straddle_high'].max():,.2f}
Straddle L {df['straddle_low'].min():,.2f}
Straddle C {current_straddle:,.2f}
{straddle_change:+.2f} ({straddle_change_pct:+.2f}%)"""
        
        bbox_props = dict(boxstyle='round,pad=0.8', facecolor='#2a2a2a', 
                          edgecolor='#444444', alpha=0.9)
        
        ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, 
                verticalalignment='top', fontsize=12, fontweight='bold',
                color='#ffffff', bbox=bbox_props, fontfamily='monospace')
        
        # Add current price line indicator
        ax.axhline(y=current_straddle, color='#ff4444', linestyle='--', alpha=0.7, linewidth=1.5)
        
        # Style the spines
        for spine in ax.spines.values():
            spine.set_color('#444444')
            spine.set_linewidth(1.5)
        
        # Add legend for indicators
        if indicators:
            ax.legend(loc='upper left', fontsize=10, framealpha=0.8, 
                     facecolor='#2a2a2a', edgecolor='#444444')
        
        plt.tight_layout()
        
        # Convert plot to base64 string
        img_buffer = io.BytesIO()
        plt.savefig(img_buffer, format='png', dpi=300, bbox_inches='tight', 
                    facecolor='#1a1a1a', edgecolor='none')
        img_buffer.seek(0)
        img_base64 = base64.b64encode(img_buffer.getvalue()).decode()
        
        return img_base64
        
    except Exception as e:
        print(f"Error creating straddle chart: {e}")
        import traceback
        traceback.print_exc()
        return None
    finally:
        plt.close('all')
        plt.clf()

# ===== OPTIONS CHAIN ROUTES =====
@app.route('/get_available_dates')
def get_available_dates_route():
    """API route to get available dates for a data type and symbol"""
    data_type = request.args.get('data_type')
    symbol = request.args.get('symbol', 'nifty')
    
    if not data_type:
        return jsonify({'error': 'data_type is required'})
    
    try:
        dates = get_available_dates(data_type, symbol)
        
        if dates:
            return jsonify({
                'success': True,
                'dates': dates
            })
        else:
            return jsonify({
                'success': False,
                'dates': [],
                'error': 'No dates found for the specified data type and symbol'
            })
    
    except Exception as e:
        print(f"Error in get_available_dates_route: {e}")
        return jsonify({'error': str(e)})

def get_underlying_asset_price(date, symbol='nifty'):
    """Get the current underlying asset price (spot price) from cash tables"""
    try:
        connection = get_db_connection()
        if not connection:
            print("Failed to connect to database for underlying price")
            return None
            
        cursor = connection.cursor()
        db_date = convert_date_to_db_format(date)
        
        if not db_date:
            print("Invalid date format for underlying price")
            cursor.close()
            connection.close()
            return None
        
        # Map symbols to cash tables
        cash_table_map = {
            'nifty': 'nifty_cash',
            'banknifty': 'banknifty_cash', 
            'midcpnifty': 'midcpnifty_cash',
            'sensex': 'sensex_cash'
        }
        
        cash_table = cash_table_map.get(symbol, 'nifty_cash')
        print(f"Looking for underlying price in table: {cash_table} for symbol: {symbol}")
        
        # Get the latest close price (LTP) from cash table
        query = f"""
        SELECT close 
        FROM {cash_table} 
        WHERE date = %s 
        ORDER BY time DESC 
        LIMIT 1
        """
        
        cursor.execute(query, (db_date,))
        result = cursor.fetchone()
        
        cursor.close()
        connection.close()
        
        if result and result[0]:
            # Apply the same scaling factor used elsewhere in the code (divide by 100)
            underlying_price = float(result[0]) / 100
            # Validate the price is reasonable
            if underlying_price > 0 and underlying_price < 1000000:  # Reasonable range check
                print(f"Retrieved underlying price for {symbol} on {date}: {underlying_price}")
                return underlying_price
            else:
                print(f"Invalid underlying price for {symbol} on {date}: {underlying_price}")
                return None
        else:
            print(f"No underlying price data found for {symbol} on {date}")
            return None
            
    except Exception as e:
        print(f"Error getting underlying asset price: {e}")
        return None

def validate_options_chain_inputs(date, symbol, expiry=None):
    """Validate inputs for options chain data retrieval"""
    try:
        # Validate date format
        datetime.strptime(date, '%Y-%m-%d')
        
        # Validate symbol
        valid_symbols = ['nifty', 'banknifty', 'midcpnifty', 'sensex']
        if symbol not in valid_symbols:
            raise ValueError(f"Invalid symbol: {symbol}")
        
        # Validate expiry if provided
        if expiry:
            datetime.strptime(expiry, '%Y-%m-%d')
        
        return True
    except ValueError as e:
        print(f"Validation error: {e}")
        return False

def validate_option_data(row):
    """Validate option data quality"""
    try:
        strike = float(row[0])
        ltp = float(row[1]) if row[1] is not None else 0
        volume = int(row[2]) if row[2] is not None else 0
        
        # Check for reasonable ranges
        if strike <= 0:
            return False
        if ltp < 0:
            return False
        if volume < 0:
            return False
            
        return True
    except (ValueError, TypeError):
        return False

@app.route('/get_options_chain_data')
def get_options_chain_data():
    """Get options chain data for a specific date, symbol, and expiry - CLEAN IMPLEMENTATION"""
    date = request.args.get('date')
    symbol = request.args.get('symbol', 'nifty')
    expiry = request.args.get('expiry')
    
    # Basic validation
    if not date:
        return jsonify({'error': 'Date is required'})
    
    connection = None
    cursor = None
    try:
        # Table mapping
        table_map = {
            'nifty': {'call_table': 'nifty_call', 'put_table': 'nifty_put'},
            'banknifty': {'call_table': 'banknifty_call', 'put_table': 'banknifty_put'},
            'midcpnifty': {'call_table': 'midcpnifty_call', 'put_table': 'midcpnifty_put'},
            'sensex': {'call_table': 'sensex_call', 'put_table': 'sensex_put'}
        }
        
        symbol_tables = table_map.get(symbol, table_map['nifty'])
        call_table = symbol_tables['call_table']
        put_table = symbol_tables['put_table']
        
        connection = get_db_connection()
        if not connection:
            return jsonify({'error': 'Failed to connect to database'})
        
        cursor = connection.cursor()
        db_date = convert_date_to_db_format(date)
        
        if not db_date:
            return jsonify({'error': 'Invalid date format'})
        
        # Build conditions
        base_condition = "date = %s"
        query_params = [db_date]
        
        if expiry:
            db_expiry = convert_date_to_db_format(expiry)
            base_condition += " AND expiry = %s"
            query_params.append(db_expiry)
        
        # SIMPLE QUERY: Get current day data with proper LTP calculation
        call_query = f"""
        SELECT 
            strike,
            (SELECT close FROM {call_table} t2 
             WHERE t2.strike = t1.strike AND t2.date = t1.date 
             ORDER BY t2.time DESC LIMIT 1) as ltp,
            SUM(volume) as volume,
            MIN(open) as day_open,
            MAX(close) as day_close
        FROM {call_table} t1
        WHERE {base_condition}
        GROUP BY strike 
        ORDER BY strike
        """
        
        put_query = f"""
        SELECT 
            strike,
            (SELECT close FROM {put_table} t2 
             WHERE t2.strike = t1.strike AND t2.date = t1.date 
             ORDER BY t2.time DESC LIMIT 1) as ltp,
            SUM(volume) as volume,
            MIN(open) as day_open,
            MAX(close) as day_close
        FROM {put_table} t1
        WHERE {base_condition}
        GROUP BY strike 
        ORDER BY strike
        """
        
        # Execute queries
        cursor.execute(call_query, query_params)
        call_results = cursor.fetchall()
        
        cursor.execute(put_query, query_params)
        put_results = cursor.fetchall()
        
        print(f"Call results: {len(call_results)}, Put results: {len(put_results)}")
        
        # Get previous day data for comparison
        prev_date_query = f"SELECT DISTINCT date FROM {call_table} WHERE date < %s ORDER BY date DESC LIMIT 1"
        cursor.execute(prev_date_query, [db_date])
        prev_date_result = cursor.fetchone()
        
        prev_call_data = {}
        prev_put_data = {}
        
        if prev_date_result:
            prev_date = prev_date_result[0]
            print(f"Previous trading day: {prev_date}")
            
            # Get previous day call data
            prev_call_query = f"""
            SELECT strike, MAX(close) as prev_close
            FROM {call_table} 
            WHERE date = %s
            GROUP BY strike
            """
            cursor.execute(prev_call_query, [prev_date])
            prev_call_results = cursor.fetchall()
            prev_call_data = {row[0]: row[1] for row in prev_call_results}
            
            # Get previous day put data
            prev_put_query = f"""
            SELECT strike, MAX(close) as prev_close
            FROM {put_table} 
            WHERE date = %s
            GROUP BY strike
            """
            cursor.execute(prev_put_query, [prev_date])
            prev_put_results = cursor.fetchall()
            prev_put_data = {row[0]: row[1] for row in prev_put_results}
        
        # Process call options
        call_data = {}
        for row in call_results:
            strike = float(row[0])
            ltp = float(row[1]) if row[1] is not None else 0
            volume = int(row[2]) if row[2] is not None else 0
            day_open = float(row[3]) if row[3] is not None else 0
            
            # Calculate change: Current LTP vs Previous day's close (standard options chain practice)
            prev_close = prev_call_data.get(strike, 0)
            if prev_close > 0:
                change = ltp - prev_close
                change_percent = (change / prev_close) * 100
            else:
                # No previous day data - use day open as fallback
                change = ltp - day_open
                change_percent = (change / day_open) * 100 if day_open > 0 else 0
            
            call_data[strike] = {
                'ltp': ltp,
                'volume': volume,
                'change': change,
                'change_percent': change_percent
            }
            
            if ltp > 0:
                print(f"CALL - Strike {strike}: prev_close={prev_close}, ltp={ltp}, change={change:.2f}, change%={change_percent:.2f}")
        
        # Process put options
        put_data = {}
        for row in put_results:
            strike = float(row[0])
            ltp = float(row[1]) if row[1] is not None else 0
            volume = int(row[2]) if row[2] is not None else 0
            day_open = float(row[3]) if row[3] is not None else 0
            
            # Calculate change: Current LTP vs Previous day's close (standard options chain practice)
            prev_close = prev_put_data.get(strike, 0)
            if prev_close > 0:
                change = ltp - prev_close
                change_percent = (change / prev_close) * 100
            else:
                # No previous day data - use day open as fallback
                change = ltp - day_open
                change_percent = (change / day_open) * 100 if day_open > 0 else 0
            
            put_data[strike] = {
                'ltp': ltp,
                'volume': volume,
                'change': change,
                'change_percent': change_percent
            }
            
            if ltp > 0:
                print(f"PUT - Strike {strike}: prev_close={prev_close}, ltp={ltp}, change={change:.2f}, change%={change_percent:.2f}")
        
        # Build options chain
        all_strikes = sorted(set(list(call_data.keys()) + list(put_data.keys())))
        options_chain = []
        
        for strike in all_strikes:
            call_info = call_data.get(strike, {'ltp': 0, 'volume': 0, 'change': 0, 'change_percent': 0})
            put_info = put_data.get(strike, {'ltp': 0, 'volume': 0, 'change': 0, 'change_percent': 0})
            
            options_chain.append({
                'strike': strike,
                'call': call_info,
                'put': put_info
            })
        
        # Summary statistics
        call_positive = sum(1 for row in options_chain if row['call']['change'] > 0)
        call_negative = sum(1 for row in options_chain if row['call']['change'] < 0)
        call_zero = sum(1 for row in options_chain if row['call']['change'] == 0)
        
        put_positive = sum(1 for row in options_chain if row['put']['change'] > 0)
        put_negative = sum(1 for row in options_chain if row['put']['change'] < 0)
        put_zero = sum(1 for row in options_chain if row['put']['change'] == 0)
        
        print(f"SUMMARY - Call: +{call_positive}, -{call_negative}, 0{call_zero} | Put: +{put_positive}, -{put_negative}, 0{put_zero}")
        
        # Get underlying asset price
        underlying_price = get_underlying_asset_price(date, symbol)
        
        print(f"=== OPTIONS CHAIN API RESPONSE DEBUG ===")
        print(f"Date: {date}")
        print(f"Symbol: {symbol}")
        print(f"Underlying Price: {underlying_price}")
        print(f"Total Strikes: {len(all_strikes)}")
        print(f"Options Chain Length: {len(options_chain)}")
        
        return jsonify({
            'success': True,
            'options_chain': options_chain,
            'total_strikes': len(all_strikes),
            'underlying_price': underlying_price
        })
        
    except Exception as e:
        print(f"Error in get_options_chain_data: {e}")
        return jsonify({'error': str(e)})
    finally:
        if cursor:
            cursor.close()
        if connection:
            connection.close()

@app.route('/test_underlying_prices')
def test_underlying_prices():
    """Test endpoint to verify underlying price retrieval for all symbols"""
    date = request.args.get('date')
    if not date:
        return jsonify({'error': 'Date is required'})
    
    symbols = ['nifty', 'banknifty', 'midcpnifty', 'sensex']
    results = {}
    
    for symbol in symbols:
        price = get_underlying_asset_price(date, symbol)
        results[symbol] = {
            'price': price,
            'status': 'success' if price else 'no_data'
        }
    
    return jsonify({
        'date': date,
        'results': results
    })

@app.route('/get_options_expiries')
def get_options_expiries():
    """Get available expiry dates for options on a specific date and symbol"""
    date = request.args.get('date')
    symbol = request.args.get('symbol', 'nifty')
    
    if not date:
        return jsonify({'error': 'Date is required'})
    
    try:
        # Determine table names based on symbol
        table_map = {
            'nifty': {
                'call_table': 'nifty_call',
                'put_table': 'nifty_put'
            },
            'banknifty': {
                'call_table': 'banknifty_call',
                'put_table': 'banknifty_put'
            },
            'midcpnifty': {
                'call_table': 'midcpnifty_call',
                'put_table': 'midcpnifty_put'
            },
            'sensex': {
                'call_table': 'sensex_call',
                'put_table': 'sensex_put'
            }
        }
        
        symbol_tables = table_map.get(symbol, table_map['nifty'])
        call_table = symbol_tables['call_table']
        put_table = symbol_tables['put_table']
        
        connection = get_db_connection()
        cursor = connection.cursor()
        db_date = convert_date_to_db_format(date)
        
        # Get expiries from both call and put tables
        cursor.execute(f"SELECT DISTINCT expiry FROM {call_table} WHERE date = %s UNION SELECT DISTINCT expiry FROM {put_table} WHERE date = %s ORDER BY expiry", (db_date, db_date))
        expiry_results = cursor.fetchall()
        
        # Convert expiry dates to readable format
        expiries = []
        for row in expiry_results:
            if row[0]:  # Check if expiry is not None
                readable_expiry = convert_db_date_to_readable(row[0])
                expiries.append({
                    'value': readable_expiry,
                    'display': readable_expiry
                })
        
        cursor.close()
        connection.close()
        
        return jsonify({
            'success': True,
            'expiries': expiries
        })
        
    except Exception as e:
        print(f"Error in get_options_expiries: {e}")
        return jsonify({'error': str(e)})

if __name__ == '__main__':
    app.run(debug=False, host='0.0.0.0', port=5000)
